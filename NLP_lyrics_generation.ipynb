{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_lyrics_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ug1e9bAP-I3L",
        "jm6NaZ5eI030"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXaqO_DLlrei"
      },
      "source": [
        "starting_word = \"rise\" #@param {type:\"string\", required: true}\n",
        "genre = \"rock\" #@param [\"rock\", \"metal\", \"blues\", \"pop\", \"rap\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i--n2RiI0p_5"
      },
      "source": [
        "# Data preparation and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fg-dw1CoAgY",
        "outputId": "6df1ae5e-272f-4eb7-8e6e-876b60a8f140"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "device_name = tf.test.gpu_device_name()# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpFF4U9L04Q0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdhEVuC3pS62",
        "outputId": "0f0058bf-227d-4b87-843b-8e0b48751443"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_to_file = '/content/drive/MyDrive/Lyrics_generator/english_cleaned_lyrics.csv'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuequEQSrLDn",
        "outputId": "a76f33c0-d797-42e8-894e-e0b6b459a651"
      },
      "source": [
        "# Load CSV data\n",
        "data = pd.read_csv(path_to_file)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Select the columns: lyrics and genre\n",
        "# columns = ['index', 'song', 'artist', 'year']\n",
        "\n",
        "# data.drop(columns, inplace=True, axis=1)\n",
        "#data.drop(data.columns[[0]], axis=1, inplace=True)\n",
        "\n",
        "data = data[['lyrics', 'genre']]\n",
        "\n",
        "# Speed up training by taking the first thousand rows (temporary)\n",
        "data = data[:1000]\n",
        "\n",
        "#print(lyrics[:10])\n",
        "#print(genre[:10])\n",
        "print(data[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              lyrics genre\n",
            "0  Oh baby how you doing You know I'm gonna cut r...   Pop\n",
            "1  playin everything so easy it's like you seem s...   Pop\n",
            "2  If you search For tenderness It isn't hard to ...   Pop\n",
            "3  Oh oh oh I oh oh oh I If I wrote a book about ...   Pop\n",
            "4  Party the people the people the party it's pop...   Pop\n",
            "5  I heard Church bells ringing I heard A choir s...   Pop\n",
            "6  This is just another day that I would spend Wa...   Pop\n",
            "7  Waiting waiting waiting waiting Waiting waitin...   Pop\n",
            "8   I read all of the magazines while waiting aro...   Pop\n",
            "9  N n now honey You better sit down and look aro...   Pop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05dujcCk7-9u"
      },
      "source": [
        "## Preprocess and split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZOKUwkJw8mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac01697-55c6-4e5e-df0f-24f79ea26349"
      },
      "source": [
        "# Lower\n",
        "def lyrics_preprocessing(lyrics_text):\n",
        "    return lyrics_text.lower() #.split()\n",
        "\n",
        "data['lyrics'] = data['lyrics'].apply(lyrics_preprocessing)\n",
        "\n",
        "# One Hot encoding\n",
        "data = pd.get_dummies(data, columns=['genre'])\n",
        "\n",
        "#print(data[:10])\n",
        "\n",
        "lyrics = data[['lyrics']]\n",
        "genres = data.iloc[:, 1:]\n",
        "\n",
        "print(lyrics[:10])\n",
        "print(genres[:10])\n",
        "\n",
        "print(genres.shape)\n",
        "genres_size = genres.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              lyrics\n",
            "0  oh baby how you doing you know i'm gonna cut r...\n",
            "1  playin everything so easy it's like you seem s...\n",
            "2  if you search for tenderness it isn't hard to ...\n",
            "3  oh oh oh i oh oh oh i if i wrote a book about ...\n",
            "4  party the people the people the party it's pop...\n",
            "5  i heard church bells ringing i heard a choir s...\n",
            "6  this is just another day that i would spend wa...\n",
            "7  waiting waiting waiting waiting waiting waitin...\n",
            "8   i read all of the magazines while waiting aro...\n",
            "9  n n now honey you better sit down and look aro...\n",
            "   genre_Country  genre_Electronic  genre_Folk  genre_Hip-Hop  genre_Indie  \\\n",
            "0              0                 0           0              0            0   \n",
            "1              0                 0           0              0            0   \n",
            "2              0                 0           0              0            0   \n",
            "3              0                 0           0              0            0   \n",
            "4              0                 0           0              0            0   \n",
            "5              0                 0           0              0            0   \n",
            "6              0                 0           0              0            0   \n",
            "7              0                 0           0              0            0   \n",
            "8              0                 0           0              0            0   \n",
            "9              0                 0           0              0            0   \n",
            "\n",
            "   genre_Jazz  genre_Metal  genre_Other  genre_Pop  genre_R&B  genre_Rock  \n",
            "0           0            0            0          1          0           0  \n",
            "1           0            0            0          1          0           0  \n",
            "2           0            0            0          1          0           0  \n",
            "3           0            0            0          1          0           0  \n",
            "4           0            0            0          1          0           0  \n",
            "5           0            0            0          1          0           0  \n",
            "6           0            0            0          1          0           0  \n",
            "7           0            0            0          1          0           0  \n",
            "8           0            0            0          1          0           0  \n",
            "9           0            0            0          1          0           0  \n",
            "(1000, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dk5OpaU3leU"
      },
      "source": [
        "# NUOVA VERSIONE TF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ59Jj9e3qPV",
        "outputId": "46e03335-ba5c-4eb7-cf7e-e8730a679f63"
      },
      "source": [
        "def split_l(x):\n",
        "  splitted = x.split()[:6]\n",
        "  if len(splitted) < 6: \n",
        "    return None\n",
        "  else:\n",
        "    return \" \".join(splitted)\n",
        "\n",
        "'''nan_values = l.isna()\n",
        "nan_columns = nan_values.any()\n",
        "print(\"Prima: \", nan_columns)'''\n",
        "\n",
        "l = data['lyrics'].apply(split_l)\n",
        "l.dropna(axis=0, inplace=True)\n",
        "\n",
        "'''nan_values = l.isna()\n",
        "nan_columns = nan_values.any()\n",
        "print(\"Dopo: \", nan_columns)'''\n",
        "#print(\"Dopo: \", l.shape)\n",
        "\n",
        "tokens = tf.strings.split(l)\n",
        "\n",
        "#tokens = data['lyrics'].apply(lambda t: tf.strings.split(t, maxsplit=5))\n",
        "\n",
        "tokens[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'oh', b'baby', b'how', b'you', b'doing', b'you'], [b'playin', b'everything', b'so', b'easy', b\"it's\", b'like'], [b'if', b'you', b'search', b'for', b'tenderness', b'it'], [b'oh', b'oh', b'oh', b'i', b'oh', b'oh'], [b'party', b'the', b'people', b'the', b'people', b'the'], [b'i', b'heard', b'church', b'bells', b'ringing', b'i'], [b'this', b'is', b'just', b'another', b'day', b'that'], [b'waiting', b'waiting', b'waiting', b'waiting', b'waiting', b'waiting'], [b'i', b'read', b'all', b'of', b'the', b'magazines'], [b'n', b'n', b'now', b'honey', b'you', b'better']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLQNpuPCMTJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e66ae32-eaf3-4adf-87f2-cc73d20dc234"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "\n",
        "#lyrics_tensor = tf.convert_to_tensor(data['lyrics'].tolist())\n",
        "\n",
        "layer = StringLookup()\n",
        "layer.adapt(tokens)\n",
        "vocab = layer.get_vocabulary()\n",
        "\n",
        "vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'i', 'you', 'a', 'to', 'in', 'and', 'my']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6F-Gul7DFRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bd7e4f-0a11-491e-d3f1-59c533a109e0"
      },
      "source": [
        "ids_from_words = layer(tokens)\n",
        "#ids_from_words = StringLookup(vocabulary=list(vocab))\n",
        "\n",
        "\n",
        "ids_from_words[:2]\n",
        "#ids = ids_from_words(tokens)\n",
        "#ids[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[17, 36, 70, 4, 556, 4], [937, 214, 41, 216, 27, 30]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCnvxzz1NjnZ",
        "outputId": "6c033fc5-4793-4104-ccef-b8176faf94a6"
      },
      "source": [
        "words_from_ids = StringLookup(\n",
        "    vocabulary=layer.get_vocabulary(), invert=True)\n",
        "#words_from_ids = StringLookup(\n",
        "#    vocabulary=ids_from_words.get_vocabulary(), invert=True)\n",
        "\n",
        "words = words_from_ids(ids_from_words)\n",
        "#words = words_from_ids(ids)\n",
        "words[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'oh', b'baby', b'how', b'you', b'doing', b'you'], [b'playin', b'everything', b'so', b'easy', b\"it's\", b'like'], [b'if', b'you', b'search', b'for', b'tenderness', b'it'], [b'oh', b'oh', b'oh', b'i', b'oh', b'oh'], [b'party', b'the', b'people', b'the', b'people', b'the'], [b'i', b'heard', b'church', b'bells', b'ringing', b'i'], [b'this', b'is', b'just', b'another', b'day', b'that'], [b'waiting', b'waiting', b'waiting', b'waiting', b'waiting', b'waiting'], [b'i', b'read', b'all', b'of', b'the', b'magazines'], [b'n', b'n', b'now', b'honey', b'you', b'better']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmcT-I0rRkh1"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(words_from_ids(ids), axis=-1, separator=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cojciCsRlvL",
        "outputId": "fa2806c7-5304-4400-c69a-8da0980b4c23"
      },
      "source": [
        "#seq_length = 32\n",
        "\n",
        "#sequences = ids_from_words.batch(seq_length, drop_remainder=True)\n",
        "\n",
        "sequences = tf.data.Dataset.from_tensor_slices(ids_from_words)\n",
        "#sequences = tf.data.Dataset.from_tensor_slices(ids)\n",
        "\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'oh baby how you doing'\n",
            "Target: b'baby how you doing you'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oprq4IKzosnB",
        "outputId": "ae7379ce-ea49-4dcf-a28d-6bbf73fe92cc"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, None), (64, None)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzFnU_r8owkX"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEp7FySKoxyr"
      },
      "source": [
        "### GENERATOR\n",
        "\n",
        "class Generator(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units, dense_size):\n",
        "      super().__init__(self)\n",
        "      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "      self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True)\n",
        "      self.dense = tf.keras.layers.Dense(dense_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "      x = inputs\n",
        "      \n",
        "      print(\"gen - shape before embedding: \", x.shape)\n",
        "      x = self.embedding(x, training=training)\n",
        "      print(\"gen - shape after embedding: \", x.shape)\n",
        "      print(\"gen - shape before gru: \", x.shape)\n",
        "      if states is None:\n",
        "        states = self.gru.get_initial_state(x)\n",
        "      x, states = self.gru(x, initial_state=states, training=training)\n",
        "\n",
        "      print(\"gen - shape after gru: \", x.shape)\n",
        "      # Dense layer with vocab_size + genres_size \n",
        "\n",
        "      print(\"gen - shape before dense: \", x.shape)\n",
        "      x = self.dense(x, training=training)\n",
        "      print(\"gen - shape after dense: \", x.shape)\n",
        "\n",
        "      if return_state:\n",
        "        return x, states\n",
        "      else: \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSdncOBJqZRM"
      },
      "source": [
        "### DISCRIMINATOR\n",
        "\n",
        "class Discriminator(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units, hidden_size):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense_one = tf.keras.layers.Dense(hidden_size)\n",
        "    self.dense_two = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    print(\"dis - shape before embedding: \", x.shape)\n",
        "    x = self.embedding(x, training=training)\n",
        "    print(\"dis - shape after embedding: \", x.shape)\n",
        "    print(\"dis - shape before gru: \", x.shape)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "\n",
        "    print(\"dis - shape after gru: \", x.shape)\n",
        "    print(\"dis - shape before flatten: \", x.shape)\n",
        "    x = self.flatten(x)\n",
        "    print(\"dis - shape after flatten: \", x.shape)\n",
        "\n",
        "    # Dense layers\n",
        "    print(\"dis - shape before dense: \", x.shape)\n",
        "    x = self.dense_one(x, training=training)\n",
        "    x = self.dense_two(x, training=training)\n",
        "    print(\"dis - shape after dense: \", x.shape)\n",
        "\n",
        "    print(\"dis - shape before sigmoid: \", x.shape)\n",
        "    x = tf.keras.activations.sigmoid(x)\n",
        "    print(\"dis - shape after sigmoid: \", x.shape)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else: \n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HKsRUUwo70P"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "gen = Generator(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    #dense_size=vocab_size + genres_size\n",
        "    dense_size=vocab_size)\n",
        "\n",
        "dis = Discriminator(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    hidden_size=32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxuLEvOlpLS4",
        "outputId": "4c99c101-c096-416c-d9b9-11b922043a1b"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions_gen = gen(input_example_batch)\n",
        "    #print(example_batch_predictions_gen, \"# example_batch_predictions_gen\")\n",
        "    print(example_batch_predictions_gen.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions_dis = dis(input_example_batch)\n",
        "    #print(example_batch_predictions_dis, \"# example_batch_predictions_dis\")\n",
        "    print(example_batch_predictions_dis.shape, \"# (batch_size, output_size)\")\n",
        "\n",
        "dis_fake_target = tf.fill(BATCH_SIZE, 0.0)\n",
        "dis_real_target = tf.fill(BATCH_SIZE, 1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "(64, 5, 1520) # (batch_size, sequence_length, vocab_size)\n",
            "dis - shape before embedding:  (64, 5)\n",
            "dis - shape after embedding:  (64, 5, 256)\n",
            "dis - shape before gru:  (64, 5, 256)\n",
            "dis - shape after gru:  (64, 5, 1024)\n",
            "dis - shape before flatten:  (64, 5, 1024)\n",
            "dis - shape after flatten:  (64, 5120)\n",
            "dis - shape before dense:  (64, 5120)\n",
            "dis - shape after dense:  (64, 1)\n",
            "dis - shape before sigmoid:  (64, 1)\n",
            "dis - shape after sigmoid:  (64, 1)\n",
            "(64, 1) # (batch_size, output_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGlmDs50BgLp",
        "outputId": "3c3c8cea-0bc4-462b-ab28-9a9dbeb49d45"
      },
      "source": [
        "gen.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  389120    \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  1558000   \n",
            "=================================================================\n",
            "Total params: 5,885,424\n",
            "Trainable params: 5,885,424\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUIeWl_EvHpG",
        "outputId": "fed733fc-74b6-4b2e-f9ff-2cd81685f10b"
      },
      "source": [
        "dis.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  389120    \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  163872    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  33        \n",
            "=================================================================\n",
            "Total params: 4,491,329\n",
            "Trainable params: 4,491,329\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzg4IfXIPEJo"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNfyUBMsByCY"
      },
      "source": [
        "# define loss functions and optimizers\n",
        "gen_loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "dis_loss = tf.losses.BinaryCrossentropy()\n",
        "\n",
        "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "dis_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP4EoUfRCvdt",
        "outputId": "173ee81e-4e1c-44ef-f571-01c476e62cdf"
      },
      "source": [
        "example_batch_loss = gen_loss(target_example_batch, example_batch_predictions_gen)\n",
        "mean_gen_loss = example_batch_predictions_gen.numpy().mean()\n",
        "\n",
        "print(\"Prediction shape: \", example_batch_predictions_gen.shape, \" # (batch_size, sequence_lenght, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_gen_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 5, 1520)  # (batch_size, sequence_lenght, vocab_size)\n",
            "Mean loss:         1.4960917e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3kUXrbU0q7m",
        "outputId": "b652c5e5-d521-4b9c-9f0a-b5aaacc6b083"
      },
      "source": [
        "example_batch_loss = dis_loss(dis_real_target, example_batch_predictions_dis)\n",
        "mean_dis_loss = example_batch_predictions_dis.numpy().mean()\n",
        "\n",
        "print(\"Prediction shape: \", example_batch_predictions_dis.shape, \" # (batch_size, output_size)\")\n",
        "print(\"Mean loss:        \", mean_dis_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 1)  # (batch_size, output_size)\n",
            "Mean loss:         0.50037855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOKE2tzkDwl3",
        "outputId": "4cc14047-53c9-48b7-a6e6-ac8a311fb90b"
      },
      "source": [
        "print(tf.exp(mean_gen_loss).numpy())\n",
        "print(tf.exp(mean_dis_loss).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.000015\n",
            "1.6493455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1iFJe72EJCF"
      },
      "source": [
        "#gen.compile(optimizer='adam', loss=gen_loss)\n",
        "#dis.compile(optimizer='adam', loss=dis_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCPir3N_EOj9"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT3QZZjFyFHL",
        "outputId": "799132bb-679d-4818-c056-f5be404f4068"
      },
      "source": [
        "def loss(model, x, y, training, loss_fn):\n",
        "  # training=training is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  y_ = model(x, training=training)\n",
        "\n",
        "  return y_, loss_fn(y_true=y, y_pred=y_)\n",
        "\n",
        "\n",
        "y_gen, gen_l = loss(gen, input_example_batch, target_example_batch, training=False, loss_fn=gen_loss)\n",
        "print(\"Gen loss test: {}\".format(gen_l))\n",
        "\n",
        "y_dis, dis_l = loss(dis, input_example_batch, dis_real_target, training=False, loss_fn=dis_loss)\n",
        "print(\"Dis loss test: {}\".format(dis_l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "Gen loss test: 7.327142238616943\n",
            "dis - shape before embedding:  (64, 5)\n",
            "dis - shape after embedding:  (64, 5, 256)\n",
            "dis - shape before gru:  (64, 5, 256)\n",
            "dis - shape after gru:  (64, 5, 1024)\n",
            "dis - shape before flatten:  (64, 5, 1024)\n",
            "dis - shape after flatten:  (64, 5120)\n",
            "dis - shape before dense:  (64, 5120)\n",
            "dis - shape after dense:  (64, 1)\n",
            "dis - shape before sigmoid:  (64, 1)\n",
            "dis - shape after sigmoid:  (64, 1)\n",
            "Dis loss test: 0.6924004554748535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upowIr1QyF_q"
      },
      "source": [
        "def grad(model, inputs, targets, loss_fn):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_, loss_value = loss(model, inputs, targets, training=True, loss_fn=loss_fn)\n",
        "  return y_, loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm73tqmW_bxy"
      },
      "source": [
        "def generate_one_step(inputs, ids_from_words, temperature=1.0):\n",
        "  # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "  skip_ids = ids_from_words(['','[UNK]'])[:, None]\n",
        "  sparse_mask = tf.SparseTensor(\n",
        "      # Put a -inf at each bad index.\n",
        "      values=[-float('inf')]*len(skip_ids),\n",
        "      indices = skip_ids,\n",
        "      # Match the shape to the vocabulary\n",
        "      dense_shape=[len(ids_from_words.get_vocabulary())]) \n",
        "      # Shape to the vocabulary + genres\n",
        "      #dense_shape=[len(ids_from_words.get_vocabulary()) + genres_size]) \n",
        "  prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  #print(\"generate_one_step - inputs: \", inputs.shape) # (batch_size, sequence_lenght, vocab_size)\n",
        "\n",
        "\n",
        "  # Only use the last prediction.\n",
        "  predicted_logits = inputs[:, -1, :]\n",
        "  predicted_logits = predicted_logits/temperature\n",
        "  # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "  predicted_logits = predicted_logits + prediction_mask\n",
        "\n",
        "  # Sample the output logits to generate token IDs.\n",
        "  predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "  predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "  # Return the predicted ids\n",
        "  return predicted_ids\n",
        "\n",
        "  '''\n",
        "  # Define a list of predicted IDs tensors (sequence_length tensors of batch_size items)\n",
        "  predicted_ids_matrix = []\n",
        "  \n",
        "  batch_size, sequence_length, _ = inputs.shape\n",
        "\n",
        "  # Predict IDs for all the predicted logits of a sequence in a batch\n",
        "  for i in range(sequence_length):\n",
        "    # Only use the i-th prediction\n",
        "    predicted_logits = inputs[:, i, :]\n",
        "    print(\"generate_one_step - inputs[:, \" + str(i) + \", :]: \", predicted_logits.shape) # (batch_size, vocab_size)\n",
        "\n",
        "    predicted_logits = predicted_logits/temperature\n",
        "    print(\"generate_one_step - inputs[:, \" + str(i) + \", :]: \", predicted_logits.shape) # (batch_size, vocab_size)\n",
        "\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + prediction_mask\n",
        "    print(\"generate_one_step - predicted_logits + prediction_mask: \", predicted_logits.shape) # (batch_size, vocab_size)\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    print(\"generate_one_step - predicted_ids: \", predicted_ids.shape) # (batch_size, 1)\n",
        "\n",
        "    # Append the predicted IDs tensor to the list\n",
        "    predicted_ids_matrix.append(predicted_ids) \n",
        "\n",
        "\n",
        "  # predicted_ids_matrix now includes sequence_length tensors of batch_size items\n",
        "  # We want batch_size tensors of sequence_length items by grouping element on the axis 1!\n",
        "\n",
        "  #print(\"predicted_ids_matrix: \", predicted_ids_matrix)\n",
        "  predicted_ids_matrix = tf.stack(predicted_ids_matrix, axis=1)\n",
        "  #print(\"predicted_ids_matrix stack: \", predicted_ids_matrix)\n",
        "  predicted_ids_matrix = tf.squeeze(predicted_ids_matrix, axis=-1)\n",
        "  #print(\"predicted_ids_matrix squeeze: \", predicted_ids_matrix)\n",
        "  print(\"generate_one_step - predicted_ids_matrix.shape: \", predicted_ids_matrix.shape) # (batch_size, sequence_lenght)\n",
        "\n",
        "  # Return the predicted IDs matrix \n",
        "  return predicted_ids_matrix'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_5o-uYTweXF"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "SEQUENCE_LENGTH = 5\n",
        "\n",
        "def train(gen, dis, dataset, epochs=20):\n",
        "  train_loss_results_gen = []\n",
        "  train_loss_results_dis = []\n",
        "  train_accuracy_results_gen = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    epoch_loss_avg_gen = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy_gen = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    epoch_loss_avg_dis = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy_dis = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    epoch_num = 1\n",
        "\n",
        "    for input_batch, target_batch in tqdm(dataset):\n",
        "      '''print(\"\\n********************************\\n\\nepoch: \", epoch_num)\n",
        "      #print(\"input_batch: \", input_batch)\n",
        "      y_gen, gen_l, gen_grad = grad(gen, input_batch, target_batch, gen_loss)\n",
        "\n",
        "      gen_optimizer.apply_gradients(zip(gen_grad, gen.trainable_variables))'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      #gen_l    = 0\n",
        "      #gen_grad = 0\n",
        "\n",
        "      # Define a list of predicted IDs tensors (sequence_length tensors of batch_size items)\n",
        "      y_gen_seq = input_batch.numpy()\n",
        "      #print(\"y_gen_seq: \", y_gen_seq)\n",
        "\n",
        "      for i in range(SEQUENCE_LENGTH):\n",
        "        # If first iteration, than train\n",
        "        if i == 0:\n",
        "          print(\"\\n********************************\\n\\nepoch: \", epoch_num)\n",
        "          #print(\"input_batch: \", input_batch)\n",
        "          y_gen, gen_l, gen_grad = grad(gen, input_batch, target_batch, gen_loss)\n",
        "\n",
        "          gen_optimizer.apply_gradients(zip(gen_grad, gen.trainable_variables))\n",
        "        # Else generate other ids to fullfill a sequence\n",
        "        else:\n",
        "          #print(\"tf.stack(y_gen_seq).shape: \", tf.stack(y_gen_seq).shape)\n",
        "          y_gen = gen(tf.stack(y_gen_seq), training=False)\n",
        "\n",
        "        print(\"\\ny_gen.shape before one_step: \", y_gen.shape)\n",
        "        y_gen = generate_one_step(y_gen, layer)\n",
        "        print(\"y_gen.shape after one_step: \", y_gen.shape)\n",
        "\n",
        "        # Remove head of each sequence\n",
        "        y_gen_seq = np.delete(y_gen_seq, 0, axis=1)\n",
        "        #print(\"y_gen_seq after delete: \", y_gen_seq)\n",
        "        #print(\"tf.expand_dims(y_gen, axis=-1): \", tf.expand_dims(y_gen, axis=-1))\n",
        "        # Append the predicted IDs array to the list\n",
        "        y_gen_seq = np.append(y_gen_seq, tf.expand_dims(y_gen, axis=-1), axis=1)\n",
        "        #print(\"y_gen_seq: \", y_gen_seq)\n",
        "\n",
        "      # target_batch.shape must be equal to y_gen_seq.shape!\n",
        "      print(\"\\ntarget_batch: \", target_batch)\n",
        "      print(\"\\ntarget_batch.shape: \", target_batch.shape)\n",
        "      print(\"y_gen_seq: \", y_gen_seq)\n",
        "      print(\"y_gen_seq.shape: \", y_gen_seq.shape)\n",
        "\n",
        "\n",
        "      print()\n",
        "      y_dis_fake, dis_fake_l, dis_fake_grad = grad(dis, y_gen_seq, dis_fake_target, dis_loss)\n",
        "      print()\n",
        "      #y_dis_real, dis_real_l, dis_real_grad = grad(dis, input_batch, dis_real_target, dis_loss)\n",
        "      y_dis_real, dis_real_l, dis_real_grad = grad(dis, target_batch, dis_real_target, dis_loss)\n",
        "\n",
        "      # Wasserstein loss\n",
        "      dis_l = tf.reduce_mean(y_dis_fake) - tf.reduce_mean(y_dis_real)\n",
        "      print(\"dis_l: \", dis_l)\n",
        "\n",
        "      alpha = tf.random.uniform(\n",
        "          shape=[tf.shape(target_batch)[0], 5],\n",
        "          minval=0.,\n",
        "          maxval=1.\n",
        "      )\n",
        "      print(\"\\nalpha.shape: \", alpha.shape)\n",
        "\n",
        "      '''differences = y_dis_fake - y_dis_real\n",
        "      print(\"differences.shape: \", differences.shape)\n",
        "      interpolates = y_dis_real + (alpha * differences)\n",
        "      print(\"interpolates.shape: \", interpolates.shape)'''\n",
        "\n",
        "      # Cast to float to calculate the interpolation\n",
        "      y_gen_seq    = tf.cast(y_gen_seq, tf.float32)\n",
        "      target_batch = tf.cast(target_batch, tf.float32)\n",
        "\n",
        "      differences = y_gen_seq - target_batch\n",
        "      print(\"differences: \", differences)\n",
        "      print(\"differences.shape: \", differences.shape)\n",
        "      interpolates = target_batch + (alpha * differences)\n",
        "      print(\"interpolates: \", interpolates)\n",
        "      print(\"interpolates.shape: \", interpolates.shape)\n",
        "      \n",
        "      # For successive discriminator embedding\n",
        "      #interpolates = tf.cast(interpolates, tf.int64)\n",
        "      #print(\"interpolates: \", interpolates)\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        '''y_, loss_value = loss(dis, inputs, targets, training=False, loss_fn=dis_loss)\n",
        "        return y_, loss_value, tape.gradient(loss_value, model.trainable_variables)'''\n",
        "\n",
        "        #y_interpolates = dis(interpolates)\n",
        "        #print(\"y_interpolates: \", y_interpolates)\n",
        "        #gradients = tape.gradient(dis(interpolates), [interpolates])[0]\n",
        "        #gradients = tape.gradient(dis(interpolates), interpolates)\n",
        "\n",
        "        gradients = tape.gradient(dis(interpolates), dis.trainable_variables)        \n",
        "        #gradients = tape.gradient(dis_l, dis.trainable_variables)\n",
        "        \n",
        "        print(\"gradients: \", gradients)\n",
        "  \n",
        "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1, 2]))\n",
        "        gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n",
        "        dis_grad = dis_l + 10 * gradient_penalty\n",
        "\n",
        "        dis_optimizer.apply_gradients(zip(dis_grad, dis.trainable_variables))\n",
        "\n",
        "      # Track progress\n",
        "      epoch_loss_avg_gen.update_state(gen_l)\n",
        "      epoch_loss_avg_dis.update_state(dis_l)  \n",
        "      # Compare predicted label to actual label\n",
        "      # training=True is needed only if there are layers with different\n",
        "      # behavior during training versus inference (e.g. Dropout).\n",
        "      epoch_accuracy_gen.update_state(target_batch, y_gen)\n",
        "      #epoch_accuracy_dis.update_state(y, model(x))\n",
        "      epoch_accuracy_dis.update_state(dis_real_target, y_dis_real)\n",
        "      epoch_accuracy_dis.update_state(dis_fake_target, y_dis_fake)\n",
        "\n",
        "      epoch_num += 1\n",
        "\n",
        "    # End epoch\n",
        "    train_loss_results_gen.append(epoch_loss_avg_gen.result())\n",
        "    train_loss_results_dis.append(epoch_loss_avg_dis.result())\n",
        "    train_accuracy_results_gen.append(epoch_accuracy_gen.result())\n",
        "\n",
        "    print(\"\\nEpoch {:03d}: Loss gen: {:.3f}, Loss dis: {:.3f}, Accuracy gen: {:.3%}\".format(epoch,\n",
        "                                                                  epoch_loss_avg_gen.result(),\n",
        "                                                                  3, ##epoch_loss_avg_dis.result(),\n",
        "                                                                  epoch_accuracy_gen.result()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EahZhJh5HOpy",
        "outputId": "39b2585c-3a1e-4c46-eccd-b4c6bb0711d1"
      },
      "source": [
        "EPOCHS = 30 #20\n",
        "train(gen, dis, dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********************************\n",
            "\n",
            "epoch:  1\n",
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "\n",
            "y_gen.shape before one_step:  (64, 5, 1520)\n",
            "y_gen.shape after one_step:  (64,)\n",
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "\n",
            "y_gen.shape before one_step:  (64, 5, 1520)\n",
            "y_gen.shape after one_step:  (64,)\n",
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "\n",
            "y_gen.shape before one_step:  (64, 5, 1520)\n",
            "y_gen.shape after one_step:  (64,)\n",
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "\n",
            "y_gen.shape before one_step:  (64, 5, 1520)\n",
            "y_gen.shape after one_step:  (64,)\n",
            "gen - shape before embedding:  (64, 5)\n",
            "gen - shape after embedding:  (64, 5, 256)\n",
            "gen - shape before gru:  (64, 5, 256)\n",
            "gen - shape after gru:  (64, 5, 1024)\n",
            "gen - shape before dense:  (64, 5, 1024)\n",
            "gen - shape after dense:  (64, 5, 1520)\n",
            "\n",
            "y_gen.shape before one_step:  (64, 5, 1520)\n",
            "y_gen.shape after one_step:  (64,)\n",
            "\n",
            "target_batch:  tf.Tensor(\n",
            "[[  67  587   63  141   93]\n",
            " [ 327    4   35    3  342]\n",
            " [ 344  100   40    6  911]\n",
            " [  21  174   43   13 1189]\n",
            " [ 796   13  174  240    4]\n",
            " [  15   44    3   78  137]\n",
            " [ 151  898    2  430   60]\n",
            " [  11   38   60 1464   15]\n",
            " [ 323  323  117  469  117]\n",
            " [  12  217   23  125   14]\n",
            " [1388   69  332    9  170]\n",
            " [  19   76    8   54   83]\n",
            " [ 409 1411    3  269  257]\n",
            " [  31  106  255  630  239]\n",
            " [ 671   14    2  843  244]\n",
            " [ 169    3   78  333   75]\n",
            " [  29   19 1348  243  136]\n",
            " [ 112  112  198  261    6]\n",
            " [   3  371   64  255    3]\n",
            " [   9  146    4  275  259]\n",
            " [  92   31   26   27  127]\n",
            " [  12  167   12  167   12]\n",
            " [1171    6 1123  732   54]\n",
            " [   2  473   10    2  299]\n",
            " [ 894  716   12  165    3]\n",
            " [   4  105    4   88  272]\n",
            " [   2   56    6    2   56]\n",
            " [ 267    6   98    2 1009]\n",
            " [   2 1383   16  175    6]\n",
            " [  14   32  340   14   22]\n",
            " [ 620    2  867 1340  136]\n",
            " [ 533 1317 1084    3  362]\n",
            " [   4  211  213   30 1170]\n",
            " [   3  787  368  132   22]\n",
            " [  77    5  107   38  360]\n",
            " [ 338    3   69   54    4]\n",
            " [ 159    5 1390 1218  164]\n",
            " [  18   16  284   44   21]\n",
            " [  32    5 1434  789  308]\n",
            " [  74  455  220  247   47]\n",
            " [  16  282  494    8  539]\n",
            " [  49   39    8 1342    8]\n",
            " [  15   39  331   15   40]\n",
            " [   2 1375    3  185   20]\n",
            " [ 168  208   38   85   51]\n",
            " [   4  151 1216  224 1447]\n",
            " [   6  442    8  317    6]\n",
            " [ 391   82  266  212   10]\n",
            " [  14   53  131 1093   91]\n",
            " [ 147  393   99  254   25]\n",
            " [  88   29  926   26   19]\n",
            " [1099 1141   94  672    7]\n",
            " [1409  971  115   56    9]\n",
            " [ 135  549   45    3   28]\n",
            " [1191   17    2  951 1459]\n",
            " [  13  205   22    5  347]\n",
            " [ 169  458    2 1090    3]\n",
            " [  62    4  921   28   42]\n",
            " [   6 1470   55   49    5]\n",
            " [ 134  154    3  278   46]\n",
            " [  16    5   95   97  505]\n",
            " [1021  103    7 1109  706]\n",
            " [   9  146    4  275  259]\n",
            " [   7    7  131  551  438]], shape=(64, 5), dtype=int64)\n",
            "\n",
            "target_batch.shape:  (64, 5)\n",
            "y_gen_seq:  [[  93    8  184    8 1048]\n",
            " [  54    4   11  139  565]\n",
            " [ 911  167   12  167   12]\n",
            " [1189   11   12  479   32]\n",
            " [   4    9  275   91   52]\n",
            " [ 512   10    2  241   93]\n",
            " [  60  193  282    8   53]\n",
            " [  15   12   73    6   15]\n",
            " [ 117  101  469  117    4]\n",
            " [  14    2  156    7    2]\n",
            " [ 170   20    4   25  365]\n",
            " [  83  102    4   43    3]\n",
            " [ 257    3    3  295    3]\n",
            " [ 239    3  901   29    2]\n",
            " [ 244    7    2 1179   38]\n",
            " [  75   77  670    3   96]\n",
            " [ 136  136  963    2  153]\n",
            " [   6 1299  168 1142    6]\n",
            " [   3   20    6   20    3]\n",
            " [ 259    7   19   60 1019]\n",
            " [ 127    7  235  923    7]\n",
            " [ 167  178   73  178    4]\n",
            " [  54   11  115   59   11]\n",
            " [ 299   11   75  185    3]\n",
            " [   3   78    3   77  670]\n",
            " [ 272  135   54   19 1119]\n",
            " [  56 1250   10    2  299]\n",
            " [1009    6    2 1271 1096]\n",
            " [   6    2  103   11   60]\n",
            " [  32   11  188   30   18]\n",
            " [ 136  986   85  298   58]\n",
            " [ 362    7   19  461   16]\n",
            " [1170   30 1170   22    2]\n",
            " [  22  143   22    2  828]\n",
            " [ 360  558  693  178    4]\n",
            " [   2 1172 1479  101   96]\n",
            " [ 164  164  511    8  100]\n",
            " [  21  174  800   43   18]\n",
            " [ 308   14    2   30    2]\n",
            " [  47   35  215   31    3]\n",
            " [ 539  539   69  543   27]\n",
            " [   8  539   19  589  224]\n",
            " [ 331   40    8   19  266]\n",
            " [   4   54   11  139   25]\n",
            " [  51  143    6    2  457]\n",
            " [1447 1444   13  270 1036]\n",
            " [   6   11 1111    2  191]\n",
            " [  10  901   87    3   88]\n",
            " [  91  885  382 1190  993]\n",
            " [  25    6    4   79   52]\n",
            " [  19   76   69   54   83]\n",
            " [   7    5  854    7  680]\n",
            " [   9  220   56   15   69]\n",
            " [  31    3   28    4  133]\n",
            " [1459    2 1194   10 1097]\n",
            " [1218  164  164  511    8]\n",
            " [   3    3  493   11    3]\n",
            " [  42   11   75   77   53]\n",
            " [ 175   56    2   56   11]\n",
            " [  46  226   30  157   19]\n",
            " [ 505 1313   10   95  256]\n",
            " [ 706  370  147  188  119]\n",
            " [ 259    7   19 1216  224]\n",
            " [ 438   75   69   69  567]]\n",
            "y_gen_seq.shape:  (64, 5)\n",
            "\n",
            "dis - shape before embedding:  (64, 5)\n",
            "dis - shape after embedding:  (64, 5, 256)\n",
            "dis - shape before gru:  (64, 5, 256)\n",
            "dis - shape after gru:  (64, 5, 1024)\n",
            "dis - shape before flatten:  (64, 5, 1024)\n",
            "dis - shape after flatten:  (64, 5120)\n",
            "dis - shape before dense:  (64, 5120)\n",
            "dis - shape after dense:  (64, 1)\n",
            "dis - shape before sigmoid:  (64, 1)\n",
            "dis - shape after sigmoid:  (64, 1)\n",
            "\n",
            "dis - shape before embedding:  (64, 5)\n",
            "dis - shape after embedding:  (64, 5, 256)\n",
            "dis - shape before gru:  (64, 5, 256)\n",
            "dis - shape after gru:  (64, 5, 1024)\n",
            "dis - shape before flatten:  (64, 5, 1024)\n",
            "dis - shape after flatten:  (64, 5120)\n",
            "dis - shape before dense:  (64, 5120)\n",
            "dis - shape after dense:  (64, 1)\n",
            "dis - shape before sigmoid:  (64, 1)\n",
            "dis - shape after sigmoid:  (64, 1)\n",
            "dis_l:  tf.Tensor(-5.2273273e-05, shape=(), dtype=float32)\n",
            "\n",
            "alpha.shape:  (64, 5)\n",
            "differences:  tf.Tensor(\n",
            "[[ 2.600e+01 -5.790e+02  1.210e+02 -1.330e+02  9.550e+02]\n",
            " [-2.730e+02  0.000e+00 -2.400e+01  1.360e+02  2.230e+02]\n",
            " [ 5.670e+02  6.700e+01 -2.800e+01  1.610e+02 -8.990e+02]\n",
            " [ 1.168e+03 -1.630e+02 -3.100e+01  4.660e+02 -1.157e+03]\n",
            " [-7.920e+02 -4.000e+00  1.010e+02 -1.490e+02  4.800e+01]\n",
            " [ 4.970e+02 -3.400e+01 -1.000e+00  1.630e+02 -4.400e+01]\n",
            " [-9.100e+01 -7.050e+02  2.800e+02 -4.220e+02 -7.000e+00]\n",
            " [ 4.000e+00 -2.600e+01  1.300e+01 -1.458e+03  0.000e+00]\n",
            " [-2.060e+02 -2.220e+02  3.520e+02 -3.520e+02 -1.130e+02]\n",
            " [ 2.000e+00 -2.150e+02  1.330e+02 -1.180e+02 -1.200e+01]\n",
            " [-1.218e+03 -4.900e+01 -3.280e+02  1.600e+01  1.950e+02]\n",
            " [ 6.400e+01  2.600e+01 -4.000e+00 -1.100e+01 -8.000e+01]\n",
            " [-1.520e+02 -1.408e+03  0.000e+00  2.600e+01 -2.540e+02]\n",
            " [ 2.080e+02 -1.030e+02  6.460e+02 -6.010e+02 -2.370e+02]\n",
            " [-4.270e+02 -7.000e+00  0.000e+00  3.360e+02 -2.060e+02]\n",
            " [-9.400e+01  7.400e+01  5.920e+02 -3.300e+02  2.100e+01]\n",
            " [ 1.070e+02  1.170e+02 -3.850e+02 -2.410e+02  1.700e+01]\n",
            " [-1.060e+02  1.187e+03 -3.000e+01  8.810e+02  0.000e+00]\n",
            " [ 0.000e+00 -3.510e+02 -5.800e+01 -2.350e+02  0.000e+00]\n",
            " [ 2.500e+02 -1.390e+02  1.500e+01 -2.150e+02  7.600e+02]\n",
            " [ 3.500e+01 -2.400e+01  2.090e+02  8.960e+02 -1.200e+02]\n",
            " [ 1.550e+02  1.100e+01  6.100e+01  1.100e+01 -8.000e+00]\n",
            " [-1.117e+03  5.000e+00 -1.008e+03 -6.730e+02 -4.300e+01]\n",
            " [ 2.970e+02 -4.620e+02  6.500e+01  1.830e+02 -2.960e+02]\n",
            " [-8.910e+02 -6.380e+02 -9.000e+00 -8.800e+01  6.670e+02]\n",
            " [ 2.680e+02  3.000e+01  5.000e+01 -6.900e+01  8.470e+02]\n",
            " [ 5.400e+01  1.194e+03  4.000e+00  0.000e+00  2.430e+02]\n",
            " [ 7.420e+02  0.000e+00 -9.600e+01  1.269e+03  8.700e+01]\n",
            " [ 4.000e+00 -1.381e+03  8.700e+01 -1.640e+02  5.400e+01]\n",
            " [ 1.800e+01 -2.100e+01 -1.520e+02  1.600e+01 -4.000e+00]\n",
            " [-4.840e+02  9.840e+02 -7.820e+02 -1.042e+03 -7.800e+01]\n",
            " [-1.710e+02 -1.310e+03 -1.065e+03  4.580e+02 -3.460e+02]\n",
            " [ 1.166e+03 -1.810e+02  9.570e+02 -8.000e+00 -1.168e+03]\n",
            " [ 1.900e+01 -6.440e+02 -3.460e+02 -1.300e+02  8.060e+02]\n",
            " [ 2.830e+02  5.530e+02  5.860e+02  1.400e+02 -3.560e+02]\n",
            " [-3.360e+02  1.169e+03  1.410e+03  4.700e+01  9.200e+01]\n",
            " [ 5.000e+00  1.590e+02 -8.790e+02 -1.210e+03 -6.400e+01]\n",
            " [ 3.000e+00  1.580e+02  5.160e+02 -1.000e+00 -3.000e+00]\n",
            " [ 2.760e+02  9.000e+00 -1.432e+03 -7.590e+02 -3.060e+02]\n",
            " [-2.700e+01 -4.200e+02 -5.000e+00 -2.160e+02 -4.400e+01]\n",
            " [ 5.230e+02  2.570e+02 -4.250e+02  5.350e+02 -5.120e+02]\n",
            " [-4.100e+01  5.000e+02  1.100e+01 -7.530e+02  2.160e+02]\n",
            " [ 3.160e+02  1.000e+00 -3.230e+02  4.000e+00  2.260e+02]\n",
            " [ 2.000e+00 -1.321e+03  8.000e+00 -4.600e+01  5.000e+00]\n",
            " [-1.170e+02 -6.500e+01 -3.200e+01 -8.300e+01  4.060e+02]\n",
            " [ 1.443e+03  1.293e+03 -1.203e+03  4.600e+01 -4.110e+02]\n",
            " [ 0.000e+00 -4.310e+02  1.103e+03 -3.150e+02  1.850e+02]\n",
            " [-3.810e+02  8.190e+02 -1.790e+02 -2.090e+02  7.800e+01]\n",
            " [ 7.700e+01  8.320e+02  2.510e+02  9.700e+01  9.020e+02]\n",
            " [-1.220e+02 -3.870e+02 -9.500e+01 -1.750e+02  2.700e+01]\n",
            " [-6.900e+01  4.700e+01 -8.570e+02  2.800e+01  6.400e+01]\n",
            " [-1.092e+03 -1.136e+03  7.600e+02 -6.650e+02  6.730e+02]\n",
            " [-1.400e+03 -7.510e+02 -5.900e+01 -4.100e+01  6.000e+01]\n",
            " [-1.040e+02 -5.460e+02 -1.700e+01  1.000e+00  1.050e+02]\n",
            " [ 2.680e+02 -1.500e+01  1.192e+03 -9.410e+02 -3.620e+02]\n",
            " [ 1.205e+03 -4.100e+01  1.420e+02  5.060e+02 -3.390e+02]\n",
            " [-1.660e+02 -4.550e+02  4.910e+02 -1.079e+03  0.000e+00]\n",
            " [-2.000e+01  7.000e+00 -8.460e+02  4.900e+01  1.100e+01]\n",
            " [ 1.690e+02 -1.414e+03 -5.300e+01  7.000e+00  6.000e+00]\n",
            " [-8.800e+01  7.200e+01  2.700e+01 -1.210e+02 -2.700e+01]\n",
            " [ 4.890e+02  1.308e+03 -8.500e+01 -2.000e+00 -2.490e+02]\n",
            " [-3.150e+02  2.670e+02  1.400e+02 -9.210e+02 -5.870e+02]\n",
            " [ 2.500e+02 -1.390e+02  1.500e+01  9.410e+02 -3.500e+01]\n",
            " [ 4.310e+02  6.800e+01 -6.200e+01 -4.820e+02  1.290e+02]], shape=(64, 5), dtype=float32)\n",
            "differences.shape:  (64, 5)\n",
            "interpolates:  tf.Tensor(\n",
            "[[  71.06742     94.82605    159.49396     20.905502   875.00726  ]\n",
            " [ 149.18707      4.          25.353153    86.45418    378.64316  ]\n",
            " [ 744.05273    144.66348     31.058216    21.226141   629.97363  ]\n",
            " [1172.0138      25.904816    35.779453   409.02512    984.6268   ]\n",
            " [ 127.739075    11.890703   223.89886    197.3187      19.878706 ]\n",
            " [  68.15945     17.855288     2.3668332   92.11358     98.68794  ]\n",
            " [ 136.42628    436.41394    204.63014     53.27301     59.85688  ]\n",
            " [  11.456363    12.956326    64.238686   330.27966     15.       ]\n",
            " [ 166.28316    252.6025     419.94537    221.33177    103.80338  ]\n",
            " [  12.630606    65.032394    96.4092      33.788475     5.7078114]\n",
            " [ 700.53906     24.546986    83.60008     22.258724   203.47716  ]\n",
            " [  35.276657    96.18167      4.7105894   45.83251     52.256927 ]\n",
            " [ 393.40488    356.53345      3.         285.24783     81.03584  ]\n",
            " [  93.76029     36.23336    478.42633    225.34518     39.969437 ]\n",
            " [ 288.13977     11.925436     2.        1124.5878     214.3772   ]\n",
            " [  97.86437     53.73323    449.80368    133.66278     85.70769  ]\n",
            " [  62.477528    98.61649   1266.0344      87.7094     141.56573  ]\n",
            " [  45.788437  1236.6777     186.94524    595.04956      6.       ]\n",
            " [   3.         175.09665     57.54084    180.28802      3.       ]\n",
            " [ 219.84383     57.33029     17.545996   247.63165    435.1895   ]\n",
            " [ 120.1316      12.8769     180.91135    843.5694     124.70497  ]\n",
            " [ 104.505974   171.60535     33.65397    176.9389       9.074608 ]\n",
            " [ 647.52673      8.283672   963.69586    330.41925     20.26123  ]\n",
            " [ 247.54076     93.88135     51.092262   110.49019    116.049835 ]\n",
            " [ 546.48315    611.3498       8.909856   101.857086   467.28677  ]\n",
            " [ 153.90955    112.103455    27.041271    38.469643   447.56244  ]\n",
            " [  19.569643   338.85287      7.9031396    2.         137.58682  ]\n",
            " [ 675.29114      6.          34.02938    112.728264  1039.7418   ]\n",
            " [   5.784337   329.10388     80.60116    152.48625     46.757774 ]\n",
            " [  23.673685    21.138947   294.83502     22.465605    21.694298 ]\n",
            " [ 597.4615     495.55295    723.8213     599.94543     93.15904  ]\n",
            " [ 423.55386    767.5568     704.902      225.47697     24.384033 ]\n",
            " [1157.1278      64.64574    377.039       27.1532     266.41602  ]\n",
            " [  16.298717   371.05344    247.57507     29.726723   630.5649   ]\n",
            " [ 102.35399    150.27222    583.0438      52.083786   153.67476  ]\n",
            " [  53.476166   605.40594   1460.1243      68.29235     37.638752 ]\n",
            " [ 163.0308      51.457787   597.4028     892.5851     154.1239   ]\n",
            " [  19.71701     41.020145   460.71082     43.755737    20.899576 ]\n",
            " [ 124.61672      7.9340396 1299.2751     632.9104     157.30254  ]\n",
            " [  48.38279    151.1753     217.39415    180.29932     42.528957 ]\n",
            " [ 310.02872    282.69366    194.75015    427.11514    313.50928  ]\n",
            " [  36.983974   498.552       11.825019  1070.3052     166.82658  ]\n",
            " [ 317.39862     39.231834    45.718384    17.728584   120.85456  ]\n",
            " [   2.1413808  756.6215       3.0323381  156.68567     21.370132 ]\n",
            " [ 135.36917    198.26866     23.109581    84.11022     81.86726  ]\n",
            " [1192.4056     194.99057    339.62823    232.97762   1113.0359   ]\n",
            " [   6.         280.66675    198.48079    160.85318     38.458332 ]\n",
            " [ 326.56784    381.19598    220.72456    129.6968      61.480427 ]\n",
            " [  47.41912    726.11707    219.68886   1093.8809     316.57193  ]\n",
            " [ 127.93262    378.0604      52.134377    91.75839     29.37663  ]\n",
            " [  46.923275    45.071762   662.5311      40.3518      36.718727 ]\n",
            " [ 505.4677     436.31476    517.995      417.52063    135.87962  ]\n",
            " [ 465.69934    900.4691      64.287186    23.357838    25.347734 ]\n",
            " [  94.4208     505.15857     44.5309       3.8548589   51.049545 ]\n",
            " [1426.295       15.393155  1186.315      289.3318    1377.7915   ]\n",
            " [ 150.274      191.18556     79.03346    389.47174    131.947    ]\n",
            " [ 156.2732     253.06128    103.88975    551.97034      3.       ]\n",
            " [  50.51731      9.846878   166.0318      40.37464     43.152145 ]\n",
            " [ 159.72066    781.20483     38.46228     50.6002       9.977334 ]\n",
            " [  73.62748    220.3911      23.321579   167.92598     44.448334 ]\n",
            " [  43.99765    345.6162      61.464996    95.303116   368.39908  ]\n",
            " [ 923.5469     169.70795      8.752594   851.34344    695.6543   ]\n",
            " [ 140.75923     26.319847    13.546218  1023.2555     232.51897  ]\n",
            " [ 257.25928     51.636074   113.295      352.4591     560.7188   ]], shape=(64, 5), dtype=float32)\n",
            "interpolates.shape:  (64, 5)\n",
            "dis - shape before embedding:  (64, 5)\n",
            "dis - shape after embedding:  (64, 5, 256)\n",
            "dis - shape before gru:  (64, 5, 256)\n",
            "dis - shape after gru:  (64, 5, 1024)\n",
            "dis - shape before flatten:  (64, 5, 1024)\n",
            "dis - shape after flatten:  (64, 5120)\n",
            "dis - shape before dense:  (64, 5120)\n",
            "dis - shape after dense:  (64, 1)\n",
            "dis - shape before sigmoid:  (64, 1)\n",
            "dis - shape after sigmoid:  (64, 1)\n",
            "gradients:  [<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7fb75b7277d0>, <tf.Tensor: shape=(256, 3072), dtype=float32, numpy=\n",
            "array([[ 2.43873592e-06,  1.06493135e-05, -9.88425381e-06, ...,\n",
            "        -1.85133005e-03,  5.62041532e-04,  9.34582553e-04],\n",
            "       [ 3.59603678e-06, -9.53533709e-06,  1.52216599e-05, ...,\n",
            "        -3.34734190e-03,  2.10020249e-03, -1.66782970e-03],\n",
            "       [-2.15396176e-06,  7.32702688e-07,  1.93194410e-05, ...,\n",
            "         1.77368452e-03, -4.56361286e-03,  1.18578086e-03],\n",
            "       ...,\n",
            "       [-1.26693294e-07, -1.96745441e-05,  9.83244627e-06, ...,\n",
            "         8.12107231e-04,  8.14244966e-04, -2.72209523e-04],\n",
            "       [-1.23541049e-05, -8.79701929e-06, -1.82575495e-05, ...,\n",
            "        -2.08732625e-03,  1.20174570e-03, -7.61447998e-04],\n",
            "       [ 5.92128708e-06,  1.55561575e-05,  2.62931408e-05, ...,\n",
            "         1.03765971e-03,  2.10876111e-03, -6.65848202e-04]], dtype=float32)>, <tf.Tensor: shape=(1024, 3072), dtype=float32, numpy=\n",
            "array([[-1.52927740e-07,  3.21428189e-07,  3.42508315e-06, ...,\n",
            "        -3.70632857e-04, -6.39514037e-05, -3.04683217e-05],\n",
            "       [ 2.47347020e-06, -8.27758504e-06, -1.65955930e-06, ...,\n",
            "        -8.96688725e-05, -1.45692495e-04, -7.53320346e-05],\n",
            "       [-2.46725449e-06, -1.08503275e-06,  3.57341969e-06, ...,\n",
            "        -5.54490507e-05, -8.01189963e-05, -5.78022664e-05],\n",
            "       ...,\n",
            "       [ 5.38010056e-07, -2.56872937e-07,  3.28886040e-06, ...,\n",
            "        -7.81238268e-05,  1.37707786e-04, -7.80590854e-05],\n",
            "       [ 1.65545930e-06,  5.38417339e-07,  9.87490694e-07, ...,\n",
            "         3.00164666e-05, -2.78897758e-04, -1.00043784e-04],\n",
            "       [ 7.38809320e-07, -1.43071225e-06, -3.72207364e-06, ...,\n",
            "        -5.09966521e-05,  9.06618709e-07, -3.82945727e-05]], dtype=float32)>, <tf.Tensor: shape=(2, 3072), dtype=float32, numpy=\n",
            "array([[ 2.88990210e-04,  1.18806754e-04, -3.15491197e-05, ...,\n",
            "        -1.02800155e+00,  1.49259806e-01, -2.87453979e-01],\n",
            "       [ 2.88990210e-04,  1.18806754e-04, -3.15491197e-05, ...,\n",
            "        -5.14186025e-01,  7.49633908e-02, -1.43673807e-01]], dtype=float32)>, <tf.Tensor: shape=(5120, 32), dtype=float32, numpy=\n",
            "array([[-3.23883817e-03,  2.69025739e-04,  2.27209716e-03, ...,\n",
            "        -6.38202473e-05,  3.77200544e-03,  1.60521618e-03],\n",
            "       [-1.48295454e-04,  1.23177615e-05,  1.04031766e-04, ...,\n",
            "        -2.92210893e-06,  1.72707383e-04,  7.34973582e-05],\n",
            "       [ 1.16763590e-03, -9.69866815e-05, -8.19114677e-04, ...,\n",
            "         2.30078676e-05, -1.35984796e-03, -5.78697596e-04],\n",
            "       ...,\n",
            "       [-2.56494241e-04,  2.13050153e-05,  1.79934650e-04, ...,\n",
            "        -5.05412891e-06,  2.98715953e-04,  1.27122024e-04],\n",
            "       [-6.10333728e-03,  5.06957818e-04,  4.28158976e-03, ...,\n",
            "        -1.20264238e-04,  7.10804900e-03,  3.02490406e-03],\n",
            "       [-2.71648983e-03,  2.25638229e-04,  1.90566166e-03, ...,\n",
            "        -5.35275321e-05,  3.16367089e-03,  1.34633284e-03]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
            "array([-5.7191777 ,  0.47504857,  4.0120945 , -0.76826376, -5.061592  ,\n",
            "       -1.4392643 , -4.088839  , -2.562015  , -1.5680044 ,  5.15806   ,\n",
            "       -3.2631555 , -0.32222924,  0.7421107 ,  2.570385  , -1.904728  ,\n",
            "        4.5532207 ,  2.8588133 , -5.4467287 , -2.334995  , -6.2006855 ,\n",
            "        2.7551422 , -2.9862251 , -1.9856806 ,  0.5651604 , -1.583497  ,\n",
            "        2.567574  , -6.510623  , -0.04471189, -5.657855  , -0.1126945 ,\n",
            "        6.6606493 ,  2.834509  ], dtype=float32)>, <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
            "array([[ 0.0526808 ],\n",
            "       [ 0.00601352],\n",
            "       [-0.02630575],\n",
            "       [-0.00703654],\n",
            "       [-0.01059994],\n",
            "       [-0.04045   ],\n",
            "       [ 0.01632449],\n",
            "       [ 0.01303469],\n",
            "       [-0.00566841],\n",
            "       [-0.00175939],\n",
            "       [-0.01628898],\n",
            "       [-0.00208734],\n",
            "       [ 0.00709443],\n",
            "       [ 0.0192726 ],\n",
            "       [-0.01134787],\n",
            "       [ 0.03296973],\n",
            "       [ 0.04234789],\n",
            "       [ 0.00212046],\n",
            "       [-0.01908929],\n",
            "       [ 0.00357762],\n",
            "       [ 0.03572379],\n",
            "       [-0.02233374],\n",
            "       [ 0.00803936],\n",
            "       [ 0.0055185 ],\n",
            "       [ 0.00181968],\n",
            "       [-0.01179951],\n",
            "       [ 0.01146574],\n",
            "       [-0.00719477],\n",
            "       [ 0.01581595],\n",
            "       [-0.0020883 ],\n",
            "       [ 0.00603621],\n",
            "       [-0.00789643]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([15.999425], dtype=float32)>]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-67b0668ccf2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;31m#20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-154-c33105429669>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(gen, dis, dataset, epochs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradients: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mslopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mgradient_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslopes\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdis_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_l\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquare\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m  10160\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10161\u001b[0m       return square_eager_fallback(\n\u001b[0;32m> 10162\u001b[0;31m           x, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m  10163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10164\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquare_eager_fallback\u001b[0;34m(x, name, ctx)\u001b[0m\n\u001b[1;32m  10194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10195\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquare_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10196\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10197\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10198\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# not list allowed dtypes, in which case we should skip this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallowed_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;31m# If we did not match an allowed dtype, try again with the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# dtype. This could be because we have an empty tensor and thus we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1523\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0;31m# convertible-to-tensor types, such as numpy arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           elems_as_tensors.append(\n\u001b[0;32m-> 1460\u001b[0;31m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0m\u001b[1;32m   1461\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow.python.framework.indexed_slices.IndexedSlices object at 0x7fb75b7277d0>) with an unsupported type (<class 'tensorflow.python.framework.indexed_slices.IndexedSlices'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2pTI5O8EUFg"
      },
      "source": [
        "#EPOCHS = 20\n",
        "\n",
        "#history = gen.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pABK0FehOj01"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, words_from_ids, ids_from_words, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature=temperature\n",
        "    self.model = model\n",
        "    self.words_from_ids = words_from_ids\n",
        "    self.ids_from_words = ids_from_words\n",
        "\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_words(['','[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices = skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_words.get_vocabulary())]) \n",
        "        # Shape to the vocabulary + genres\n",
        "        #dense_shape=[len(ids_from_words.get_vocabulary()) + genres_size]) \n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    '''input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_words(input_chars).to_tensor())'''\n",
        "    input_ids = self.ids_from_words([inputs])\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits] \n",
        "    predicted_logits, states =  self.model(inputs=input_ids, \n",
        "                                           states=states, \n",
        "                                           return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_words = self.words_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_words, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uFRGB5NPbGq"
      },
      "source": [
        "#one_step_model = OneStep(model, words_from_ids, ids_from_words)\n",
        "#one_step_model = OneStep(model, words_from_ids, layer)\n",
        "\n",
        "one_step_model = OneStep(gen, words_from_ids, layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqHyrvTOTc9q"
      },
      "source": [
        "start  = time.time()\n",
        "states = None\n",
        "next_word = tf.constant(['romeo'])\n",
        "result    = [next_word]\n",
        "\n",
        "for n in range(100):\n",
        "  next_word, states = one_step_model.generate_one_step(next_word, states=states)\n",
        "  result.append(next_word)\n",
        "\n",
        "print(tf.strings.join(result, separator=\" \")[0].numpy().decode(\"utf-8\"))\n",
        "end    = time.time()\n",
        "\n",
        "print(f\"\\nRun time: {end - start}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPkdGDnaF0F_"
      },
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GGyNSJoF3UZ"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['love'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result, separator=\" \")[0].numpy().decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg7d9ZtOB1xH"
      },
      "source": [
        "# VECCHIA VERSIONE TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug1e9bAP-I3L"
      },
      "source": [
        "## Vectorize the lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSw1_0AyVd_7"
      },
      "source": [
        "# Build the Vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Init\n",
        "vectorize_layer = TextVectorization(\n",
        "    output_mode='int',\n",
        "    output_sequence_length=50)\n",
        "\n",
        "# Load data as TF Dataset object\n",
        "tf_lyrics = tf.data.Dataset.from_tensor_slices(lyrics)\n",
        "tf_genre = tf.data.Dataset.from_tensor_slices(genre)\n",
        "\n",
        "# Fit the Vectorizer\n",
        "vectorize_layer.adapt(tf_lyrics.batch(1024))\n",
        "inverse_vocab = vectorize_layer.get_vocabulary()\n",
        "\n",
        "ids_from_chars = StringLookup(\n",
        "    vocabulary=inverse_vocab)\n",
        "\n",
        "# Traform (vectorize) the lyrics\n",
        "def vectorize_text(text):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return tf.squeeze(vectorize_layer(text))\n",
        "\n",
        "# Vectorize the data in text_ds.\n",
        "tf_vec_lyrics = tf_lyrics.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer)\n",
        "\n",
        "ids = ids_from_chars(tf_vec_lyrics)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeCckay6AGUC"
      },
      "source": [
        "# Build the Vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Init\n",
        "vectorize_layer = TextVectorization(\n",
        "    output_mode='int',\n",
        "    output_sequence_length=50)\n",
        "\n",
        "# Load data as TF Dataset object\n",
        "tf_lyrics = tf.data.Dataset.from_tensor_slices(lyrics)\n",
        "tf_genre = tf.data.Dataset.from_tensor_slices(genre)\n",
        "\n",
        "# Fit the Vectorizer\n",
        "vectorize_layer.adapt(tf_lyrics.batch(1024))\n",
        "\n",
        "# Save the inverse vocabulary\n",
        "inverse_vocab = vectorize_layer.get_vocabulary()\n",
        "print(inverse_vocab[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnb01OZJSAx9"
      },
      "source": [
        "'''\n",
        "# Traform (vectorize) the lyrics\n",
        "def vectorize_text(text):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return tf.squeeze(vectorize_layer(text))\n",
        "\n",
        "# Vectorize the data in text_ds.\n",
        "tf_vec_lyrics = tf_lyrics.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()\n",
        "\n",
        "# Print the vectorized text\n",
        "sequences = list(tf_vec_lyrics.as_numpy_iterator())\n",
        "             \n",
        "print(len(sequences))\n",
        "\n",
        "#for seq in sequences[:5]:\n",
        "#  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDrFcDdhCy1m"
      },
      "source": [
        "# Transform (vectorize) the lyrics\n",
        "def vectorize_text(text):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return tf.squeeze(vectorize_layer(text))\n",
        "\n",
        "# Vectorize the data in text_ds.\n",
        "tf_vec_lyrics = tf_lyrics.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()\n",
        "\n",
        "# Print the vectorized text\n",
        "sequences = tf_vec_lyrics.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "#print(len(sequences))\n",
        "\n",
        "for seq in sequences[:5]:\n",
        "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5LAfRdzSz2P"
      },
      "source": [
        "ids_from_terms = preprocessing.StringLookup(\n",
        "    vocabulary=list(inverse_vocab))\n",
        "\n",
        "ids = ids_from_terms(tf_lyrics)\n",
        "\n",
        "terms_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_terms.get_vocabulary(), invert=True)\n",
        "\n",
        "terms = terms_from_ids(ids)\n",
        "\n",
        "tf.strings.reduce_join(terms, axis=-1).numpy()\n",
        "\n",
        "\n",
        "\n",
        "def text_from_ids(term):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhTuR3zFQFla"
      },
      "source": [
        "def split_input_target(lyrics):\n",
        "    input_text = lyrics[:-1]\n",
        "    target_text = lyrics[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPCbV4iAQQsk"
      },
      "source": [
        "tf_vec_lyrics = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T83naHTdQfYt"
      },
      "source": [
        "for input_example, target_example in tf_vec_lyrics.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geQdh-AbNd6l"
      },
      "source": [
        "'''\n",
        "ids_from_terms = preprocessing.StringLookup(\n",
        "    vocabulary=list(inverse_vocab))\n",
        "\n",
        "ids = ids_from_terms(terms)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)\n",
        "\n",
        "chars = chars_from_ids(ids)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JpQXAnJIk-G"
      },
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "#seq_length = 10\n",
        "#examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "#char_dataset = tf.data.Dataset.from_tensor_slices(list(text_vector_ds.as_numpy_iterator())[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUYQqaK5ONkv"
      },
      "source": [
        "#sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "#def split_input_target(chunk):\n",
        "#    input_text = chunk[:-1]\n",
        "#    target_text = chunk[1:]\n",
        "#    return input_text, target_text\n",
        "\n",
        "#dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm6NaZ5eI030"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82zFYEtVClXz"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "tf_vec_lyrics = tf_vec_lyrics.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je5sxJTCPTm8"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(inverse_vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True, \n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else: \n",
        "      return x\n",
        "\n",
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(inverse_vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSBbio7CJOuy"
      },
      "source": [
        "'''\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size=len(inverse_vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-NT2GimPcFE"
      },
      "source": [
        "#example_batch_predictions = 0\n",
        "\n",
        "#for input_example_batch, target_example_batch in tf_vec_lyrics.take(1):\n",
        "#    example_batch_predictions = model(input_example_batch)\n",
        "#    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "#model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0exo2zD3EbTW"
      },
      "source": [
        "tf_vec_lyrics.batch(50, drop_remainder = True)\n",
        "\n",
        "for lyric in tf_vec_lyrics.take(1):\n",
        "  example_batch_predictions = model(lyric)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK7BwXDJMqFc"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8el5dut9NJ67"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
