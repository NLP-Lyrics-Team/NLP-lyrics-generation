{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyrics preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da70938be87346229967772c6546748e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b4a5341b334418abf7b30aa27940e87",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef839d77386945a2970ce11d03521c86",
              "IPY_MODEL_cae8840bd5d94382b611d85e8852559f",
              "IPY_MODEL_f174251a996d44a0aa900ef2b4c03e02"
            ]
          }
        },
        "5b4a5341b334418abf7b30aa27940e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef839d77386945a2970ce11d03521c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b8b168d794841dbbc8ced30f78d5e8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b55c0db0c61408fa0aa579ab1ecf8e3"
          }
        },
        "cae8840bd5d94382b611d85e8852559f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d59287e1aa64125be89f17c4ed39c8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2000000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2000000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae041f2d5ed9428085cd87f80bd4c928"
          }
        },
        "f174251a996d44a0aa900ef2b4c03e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ef9f2f84db44040a08bc4bf8ac6fae8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000000/2000000 [01:30&lt;00:00, 31390.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d300e3acd7424843bde31a62ef86faa6"
          }
        },
        "2b8b168d794841dbbc8ced30f78d5e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b55c0db0c61408fa0aa579ab1ecf8e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d59287e1aa64125be89f17c4ed39c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae041f2d5ed9428085cd87f80bd4c928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ef9f2f84db44040a08bc4bf8ac6fae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d300e3acd7424843bde31a62ef86faa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9416bf996901492d9efb3e498a1fb15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26f11d044c7a4c23beaa4daaea928d2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e213db49d0fa4dfc808a938d51f54de6",
              "IPY_MODEL_be6f8664e93145508c4bb6c36c3e59aa",
              "IPY_MODEL_1765dbd7266b46bfbb201c8531b8046d"
            ]
          }
        },
        "26f11d044c7a4c23beaa4daaea928d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e213db49d0fa4dfc808a938d51f54de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a0e8e194e0c4ca4ad0d5fc58adbad6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 58%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5ac8b76a70e46dda87f1da1c9c0f78d"
          }
        },
        "be6f8664e93145508c4bb6c36c3e59aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5cfe82bff89d4ce1885dbe203bced643",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2000000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1169427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_210f7fbf66f64663b1071c1f57d3bd72"
          }
        },
        "1765dbd7266b46bfbb201c8531b8046d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f3afdfa2b83142d39d8c09507c37dc5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1169427/2000000 [00:51&lt;00:51, 16039.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_541bac7093f44e2aa2ae75ef4e4d07e9"
          }
        },
        "0a0e8e194e0c4ca4ad0d5fc58adbad6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5ac8b76a70e46dda87f1da1c9c0f78d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cfe82bff89d4ce1885dbe203bced643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "210f7fbf66f64663b1071c1f57d3bd72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3afdfa2b83142d39d8c09507c37dc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "541bac7093f44e2aa2ae75ef4e4d07e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDNoQV9b4JE6"
      },
      "source": [
        "# Word2vec and vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGHcoqGgc7LC"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvVGFt6iO1so"
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7A6v-s1ctRe"
      },
      "source": [
        "Mount Google Drive to load the dataset of lyrics and the word2vec pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOQ9mojZPL_t",
        "outputId": "b9f968a3-0001-44ec-d443-8de98efc490d"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "word2vec_path = \"/content/drive/MyDrive/DM project - NLP lyrics generation/cc.en.300.vec\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FeXvUpndNbT"
      },
      "source": [
        "Check if words of interest are present in the Word2vec file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da70938be87346229967772c6546748e",
            "5b4a5341b334418abf7b30aa27940e87",
            "ef839d77386945a2970ce11d03521c86",
            "cae8840bd5d94382b611d85e8852559f",
            "f174251a996d44a0aa900ef2b4c03e02",
            "2b8b168d794841dbbc8ced30f78d5e8d",
            "9b55c0db0c61408fa0aa579ab1ecf8e3",
            "6d59287e1aa64125be89f17c4ed39c8b",
            "ae041f2d5ed9428085cd87f80bd4c928",
            "2ef9f2f84db44040a08bc4bf8ac6fae8",
            "d300e3acd7424843bde31a62ef86faa6",
            "9416bf996901492d9efb3e498a1fb15d",
            "26f11d044c7a4c23beaa4daaea928d2a",
            "e213db49d0fa4dfc808a938d51f54de6",
            "be6f8664e93145508c4bb6c36c3e59aa",
            "1765dbd7266b46bfbb201c8531b8046d",
            "0a0e8e194e0c4ca4ad0d5fc58adbad6b",
            "b5ac8b76a70e46dda87f1da1c9c0f78d",
            "5cfe82bff89d4ce1885dbe203bced643",
            "210f7fbf66f64663b1071c1f57d3bd72",
            "f3afdfa2b83142d39d8c09507c37dc5b",
            "541bac7093f44e2aa2ae75ef4e4d07e9"
          ]
        },
        "id": "aIqS5Vu3a1Yr",
        "outputId": "c133e363-7c3e-4b11-8c5e-9911e8af9999"
      },
      "source": [
        "# OLD VERSION WHERE VOCABULARY WAS CREATED WITHOUT EXCLUSIVELY USING DATASET WORDS\n",
        "'''# Create dictionary and word vector list for word embeddings\n",
        "VOCABULARY_LEN = 390_000\n",
        "VECTOR_SIZE    = 300\n",
        "\n",
        "# Create dictionary and inverse dictionary of words and word vector list for word embeddings\n",
        "words2indices = {}\n",
        "indices2words = {}\n",
        "word_vectors = []\n",
        "\n",
        "# Append padding vector to the word_vectors (pad is at position 0)\n",
        "word_vectors.append(torch.rand(VECTOR_SIZE))\n",
        "\n",
        "# Append unknown vector to the word_vectors (unk is at position 1)\n",
        "word_vectors.append(torch.rand(VECTOR_SIZE))\n",
        "\n",
        "# Word2vec file contains words (including punctuation and contractions) with some permutations of lower and upper case letters,\n",
        "# so don't worry about the case that a word may be present only in uppercase letters\n",
        "\n",
        "# Take just a subset of the words that start with an apostrophe\n",
        "contractions = { \"'bout\", \"'cause\", \"'cos\", \"'coz\", \"'cuz\", \"'fore\", \"'em\", \"'nuff\", \"'round\",  \"'til\", \"'till\" }\n",
        "\n",
        "print(\"Creating vocabulary using Word2vec pre-trained embedding...\\n\")\n",
        "\n",
        "with open(word2vec_path) as f:\n",
        "    next(f) \n",
        "    #for i, l in tqdm(enumerate(f), total=2000000):\n",
        "    for l in tqdm(f, total=2_000_000):\n",
        "        # Check if the desired vocabulary size has been achieved\n",
        "        if len(word_vectors) == VOCABULARY_LEN:\n",
        "          print(\"Desired vocabulary size achieved, stop vectors iterations!\")\n",
        "          break\n",
        "\n",
        "        # Get the word and the corresponding vector\n",
        "        word, *vector = l.strip().split()\n",
        "\n",
        "        # Check if a word is in the word2vec file\n",
        "        #if word.lower() == 'i':\n",
        "        #if word.lower() in punctuation:\n",
        "        #if word.lower() in contractions:\n",
        "        #if \"'\" in word:\n",
        "        #if \"’\" in word:\n",
        "        #if word.isdigit():\n",
        "        #if re.match(\"^[a-z]+'*[a-z]*$\", word):\n",
        "        #if re.match(\"^[0-9]+$|^(19|20)[0-9]{1}0s$|^[0-9]0s$\", word):\n",
        "        #if re.match(\"^[0-9]{1}x$|^x[0-9]{1}$\", word):\n",
        "        #if word.lower() == \"i've\" or word.lower() == \"ain't\": # In Word2vec vectors, only I've is present while the lyrics include both i've and ain't\n",
        "        #if word[len(word)-1] == \"'\":                          # In Word2vec vectors, no 'ing' ending contraction is present while the lyrics include them (e.g., crying -> cryin')\n",
        "        #if word[len(word)-2:] == \"'s\":                        # In Word2vec vectors, no decade in the form XX's is present (e.g., 60's)\n",
        "        #if re.match(\"^[0-9]+s$\", word):                       # But are present in the form XXXXs or XXs, so we can use one of the two or both representations\n",
        "        #  print(\"word: \", word)\n",
        "        #else:\n",
        "        #  continue\n",
        "\n",
        "        # Skip words composed of at least one upper case or non-alpha letter (except contractions ,numbers and decades)\n",
        "        if re.match(\"^[a-z]+'*[a-z]*$\", word) or re.match(\"^[0-9]+$|^(19|20)[0-9]{1}0s|^[0-9]0s$$\", word) or word in contractions:\n",
        "          #print(\"Added word: \", word)\n",
        "\n",
        "          # Convert to float the word's vector values\n",
        "          vector = torch.tensor([float(c) for c in vector])\n",
        "          \n",
        "          # Calculate the word's index and add it and the word in the corresponding dictionaries\n",
        "          word_idx = len(word_vectors)\n",
        "          words2indices[word]     = word_idx\n",
        "          indices2words[word_idx] = word\n",
        "\n",
        "          # Append the word's vector to the list of vectors\n",
        "          word_vectors.append(vector)\n",
        "\n",
        "word_vectors = torch.stack(word_vectors)\n",
        "\n",
        "# Try to move word_vectors on the GPU \n",
        "if torch.cuda.is_available():\n",
        "  word_vectors.cuda()\n",
        "\n",
        "print(\"Vocabulary created\")'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test if the following words are present in the word2vec file (useful for lyrics preprocessing)\n",
        "test = { \n",
        "  \"'s\", \"'d\",\n",
        "  \"abouts\", \"abuse\", \"across\", \"ain't\", \"aiyo\", \"alabama\", \"alright\", \"ancient\", \"announced\", \"appeared\", \"arizona\", \"assquake\", \"awfully\", \\\n",
        "  \"backas\", \"banished\", \"bean\", \"beneath\", \"beyoncé\", \"bidness\", \"bigga\", \"billions\", \"bloodletting\", \"Brigadoon\", \"Brignac\", \"brilliant\", \"buzzy\", \\\n",
        "  \"calledst\", \"cadillac\", \"can't\", \"cah\", \"cating\", \"causе\", \"children\", \"chiraq\", \"cliche\", \"closa\", \"coolest\", \"Cobain\", \"copy\", \"crackhead\", \"creeping\", \"cuz\", \\\n",
        "  \"d'usse\", \"Dahrouge\", \"Defari\", \"delphinidin\", \"desiree\", \"dеtroit\", \"dirt\", \"dolemite\", \"don't\", \"dookie\", \"dope\", \"drooned\", \"dr.\", \\\n",
        "  \"'em\", \"embroiled\", \"except\", \\\n",
        "  \"fa\", \"feared\", \"finally\", \"frightening\", \"f**k\", \"fucking\", \\\n",
        "  \"gats\", \"gi\", \"gonna\", \"gorgeous\", \"gotta\", \"grabba\", \"groceries\", \"gster\", \\\n",
        "  \"halfpennies\", \"hallucinogen\", \"hast\", \"ho\", \\\n",
        "  \"irregular\", \\\n",
        "  \"jag\", \\\n",
        "  \"karat\", \"keep\", \"Khalil\", \"kilos\", \\\n",
        "  \"Lativia\", \"lightning\", \"lil\", \"lingering\", \"locked\", \"looed\", \"looters\",\"loser\", \"logically\", \"lolo\", \"louisiana\", \\\n",
        "  \"mackerel\", \"madam\", \"memba\", \"mercedes\", \"mil\", \"mississippi\", \"monsta\", \"mothafucka\", \"mothafuckers\", \"motherfucker\", \"motherfuckers\", \"motherfucking\", \"mr\", \"mr.\", \"mrs.\", \"ms.\", \\\n",
        "  \"named\", \"naturally\", \"norsemen\", \"northwester\", \"north\", \"nourished\", \\\n",
        "  \"oclock\", \"orleannais\", \"Oshun\", \"ough\", \\\n",
        "  \"philistines\", \"pile\", \"pining\", \"played\", \"Portmore\", \"prof.\", \"profitable\", \"psychedelically\", \\\n",
        "  \"quicka\", \\\n",
        "  \"Rafah\", \"RnB\", \"restored\", \"ruled\", \\\n",
        "  \"scrambling\", \"screeching\", \"scuse\", \"shocking\", \"slippery\", \"smiled\", \"smouldering\", \"sovereign\", \"spinning\", \"strawberries\", \"strengthened\", \"suffering\", \"sumn\", \\\n",
        "  \"taken\", \"tho\", \"thou\", \"thrilla\", \"tobacco\", \"tow\", \"traveling\", \"travellin\", \"trembling\", \"trigga\", \"tryna\", \"twerk\", \\\n",
        "  \"unleash\", \"unutterable\", \\\n",
        "  \"Vedder\", \\\n",
        "  \"wanderer\", \"wandering\", \"wantcha\", \"wester\", \"wha\", \"whatevs\", \"whatna\", \"wondering\", \\\n",
        "  \"ya\", \"Yamazaki\", \"yo\", \\\n",
        "  \"...\", \"…\", \",\", \".\", \";\", \":\", \"?\", \"!\", \"$\", \"/\", \"(\", \")\", \" \", \"\\n\" }\n",
        "\n",
        "found = set()\n",
        "\n",
        "print(\"Scanning Word2vec pre-trained embedding looking for missing words...\\n\")\n",
        "\n",
        "with open(word2vec_path) as f:\n",
        "    next(f) \n",
        "    for l in tqdm(f, total=2_000_000):\n",
        "        # Get the word and the corresponding vector\n",
        "        word, *vector = l.strip().split()\n",
        "\n",
        "        if word in test:\n",
        "          found.add(word)\n",
        "          #print(\"word: \", word)\n",
        "\n",
        "missing_words = test.difference(found)\n",
        "print(\"%d missing words\" %len(missing_words))\n",
        "\n",
        "for word in missing_words:\n",
        "  if word == \"\\n\":\n",
        "    word = \"newline\"\n",
        "  elif word == \" \":\n",
        "    word = \"whitespace\"\n",
        "  print(\"missing word: \", word)\n",
        "  \n",
        "print(\"\\nScanning Word2vec pre-trained embedding trying to find previous missing words ignoring capitalization...\\n\")\n",
        "\n",
        "with open(word2vec_path) as f:\n",
        "    next(f) \n",
        "    for l in tqdm(f, total=2_000_000):\n",
        "        # Get the word and the corresponding vector\n",
        "        word, *vector = l.strip().split()\n",
        "\n",
        "        if word.lower() in missing_words:\n",
        "          print(\"Required word is not present but ignoring capitalization there is: \", word)#'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning Word2vec pre-trained embedding looking for missing words...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da70938be87346229967772c6546748e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2000000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26 missing words\n",
            "missing word:  f**k\n",
            "missing word:  dolemite\n",
            "missing word:  assquake\n",
            "missing word:  chiraq\n",
            "missing word:  closa\n",
            "missing word:  mothafuckers\n",
            "missing word:  whitespace\n",
            "missing word:  d'usse\n",
            "missing word:  wantcha\n",
            "missing word:  drooned\n",
            "missing word:  norsemen\n",
            "missing word:  R&B\n",
            "missing word:  dеtroit\n",
            "missing word:  quicka\n",
            "missing word:  Dahrouge\n",
            "missing word:  newline\n",
            "missing word:  R'n'B\n",
            "missing word:  causе\n",
            "missing word:  Lativia\n",
            "missing word:  whatna\n",
            "missing word:  orleannais\n",
            "missing word:  ain't\n",
            "missing word:  grabba\n",
            "missing word:  calledst\n",
            "missing word:  northwester\n",
            "missing word:  gster\n",
            "\n",
            "Scanning Word2vec pre-trained embedding trying to find previous missing words ignoring capitalization...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9416bf996901492d9efb3e498a1fb15d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2000000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required word is not present but ignoring capitalization there is:  Norsemen\n",
            "Required word is not present but ignoring capitalization there is:  Dolemite\n",
            "Required word is not present but ignoring capitalization there is:  Chiraq\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c088a517f5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2_000_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Get the word and the corresponding vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAfU-NbJp4sY"
      },
      "source": [
        "# Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8WhjM-jreeR"
      },
      "source": [
        "Enter the following code in the browser console to prevent Colab to suspend current session (may no longer work from March 2021 due to captcha)\n",
        "\n",
        "```javascript\n",
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "let funId = setInterval(ConnectButton,60000);\n",
        "```\n",
        "\\\\\n",
        "Enter the following line to cancel continuous clicking\n",
        "\n",
        "```javascript\n",
        "clearInterval(funId);\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRE9DwTsYrW7"
      },
      "source": [
        "# Check python version because from 3.10 we can use match ... case\n",
        "!python3 -V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJFymW2IPru"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orJaQGwJIOX-"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Set pandas option\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8OEsAOZIbtk"
      },
      "source": [
        "Mount Google Drive to load the dataset of lyrics and the word2vec pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdB7GDrmIbtl"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "dataset_path              = \"/content/drive/MyDrive/DM project - NLP lyrics generation/genius_lyrics.csv\"\n",
        "preprocessed_dataset_path = \"/content/drive/MyDrive/DM project - NLP lyrics generation/preprocessed_lyrics.csv\"\n",
        "\n",
        "\n",
        "# TEST\n",
        "#input_dataset_path = \"/content/drive/MyDrive/DM project - NLP lyrics generation/Dataset creation notebooks/genius ok/genius_lyrics_0-50.csv\"\n",
        "#dataset_path       = \"/content/drive/MyDrive/DM project - NLP lyrics generation/preprocessed_lyrics.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt_Ta0aJsOK3"
      },
      "source": [
        "Install googletrans to detect language of a lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEQ2urvFsOK5"
      },
      "source": [
        "#!pip install googletrans==4.0.0-rc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEK53PrInMnJ"
      },
      "source": [
        "Define detecting function using googletrans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltirVxN_sOK6"
      },
      "source": [
        "'''from googletrans import Translator\n",
        "import time\n",
        "\n",
        "detector = Translator()\n",
        "MAX_SPLIT = 10\n",
        "SENTENCES_GOAL = 5\n",
        "\n",
        "# Non-stable, sometimes throw errors\n",
        "def is_english(text):\n",
        "  if not text:\n",
        "    return False\n",
        "\n",
        "  sentences = text.split(\"\\n\", MAX_SPLIT)\n",
        "  \n",
        "  i = 0\n",
        "  en_sentences = 0\n",
        "\n",
        "  for s in sentences:\n",
        "    if i == SENTENCES_GOAL:\n",
        "      break\n",
        "\n",
        "    #print(\"*\"*40)\n",
        "    #print(\"Sentence: \", s)\n",
        "\n",
        "    if s:\n",
        "      detected = detector.detect(s)\n",
        "      #print(detected)\n",
        "\n",
        "      if detected.lang == \"en\": # and detected.confidence > 0.6:\n",
        "        en_sentences += 1\n",
        "\n",
        "      i += 1\n",
        "      time.sleep(0.5) # To avoid being blocked from Google\n",
        "\n",
        "  confidence = en_sentences/i if i > 0 else 0.0\n",
        "  #print(\"\\nenglish sentences: %d/%d = %.2f\" %(en_sentences, i, confidence))\n",
        "\n",
        "  return True if confidence >= 0.8 else False\n",
        "\n",
        "\n",
        "#lyrics = \"Viva la vita\\n¿Dónde está el hombre con fuego en la sangre?\\nHe's been waiting around for the weekend\\nOK it's alright with me\\nSome things are just\\nRight about the time I missed your call\\nWhoa, whoa, whoa\\nI'm going down to the\\nI wanna hold em' like they do in texas please\\nWhatsoever I feared has\\nCome to life\"\n",
        "#print(\"Is english text?\", is_english(lyrics))'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrcKl1-1m-zL"
      },
      "source": [
        "Install textblob to detect language of a lyrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brNrpuzhsOK7",
        "outputId": "9660f72b-ddf6-4ba7-a2c4-d0e3f99c1d9b"
      },
      "source": [
        "!pip install textblob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eliTT5GqnEnI"
      },
      "source": [
        "Define detecting function using textblob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avyg67rDsOK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c71c2dc-e63d-4c2c-f937-0ffa888ae253"
      },
      "source": [
        "from textblob import TextBlob\n",
        "import time\n",
        "import random\n",
        "\n",
        "MAX_SPLIT = 30 #10\n",
        "SENTENCES_GOAL = 10 #5\n",
        "\n",
        "TOLERANCE = int(SENTENCES_GOAL * 0.2)\n",
        "\n",
        "# Return true if text is english with a certain high probability, false otherwise\n",
        "def is_english(text):\n",
        "  if not text:\n",
        "    return False\n",
        "\n",
        "  # Split the text in sentences\n",
        "  sentences = text.split(\"\\n\", MAX_SPLIT)\n",
        "\n",
        "  # Shuffle sentences to avoid taking only the beginning of text which can be misleading\n",
        "  random.shuffle(sentences)\n",
        "  \n",
        "  i = 0\n",
        "  '''en_sentences = 0\n",
        "\n",
        "  for s in sentences:\n",
        "    if i == SENTENCES_GOAL:\n",
        "      break\n",
        "\n",
        "    #print(\"*\"*40)\n",
        "    #print(\"Sentence: \", s)\n",
        "\n",
        "    if s and len(s) > 2:\n",
        "      detector = TextBlob(s)\n",
        "      lang = detector.detect_language()\n",
        "      print(\"Language: \", lang)\n",
        "\n",
        "      if lang == \"en\":\n",
        "        en_sentences += 1\n",
        "\n",
        "      i += 1\n",
        "      time.sleep(0.5) # To avoid being blocked from Google\n",
        "\n",
        "  # Calculate confidence of the english language about the text\n",
        "  confidence = en_sentences/i if i > 0 else 0.0\n",
        "  #print(\"\\nenglish sentences: %d/%d = %.2f\" %(en_sentences, i, confidence))\n",
        "  \n",
        "  return True if confidence >= 0.8 else False'''\n",
        "\n",
        "\n",
        "\n",
        "  # BETTER PERFORMANCES\n",
        "  non_en_sentences = 0\n",
        "\n",
        "  for s in sentences:\n",
        "    # Stop iterations if number of sentences goal has been reached or\n",
        "    # too many non english sentences have been detected or\n",
        "    # enough english sentences have been detected\n",
        "    if i == SENTENCES_GOAL or non_en_sentences > TOLERANCE or i-non_en_sentences == SENTENCES_GOAL-TOLERANCE:\n",
        "      break\n",
        "\n",
        "    #print(\"*\"*40)\n",
        "    #print(\"Sentence: \", s)\n",
        "\n",
        "    if s and len(s) > 2:\n",
        "      detector = TextBlob(s)\n",
        "      lang = detector.detect_language()\n",
        "      print(\"Language: \", lang)\n",
        "\n",
        "      if lang != \"en\":\n",
        "        non_en_sentences += 1\n",
        "\n",
        "      i += 1\n",
        "      time.sleep(0.5) # To avoid being blocked from Google\n",
        "\n",
        "  # Tolerate at most TOLERANCE non english sentences over SENTENCES_GOAL\n",
        "  return non_en_sentences <= TOLERANCE\n",
        "\n",
        "\n",
        "#lyrics = \"Viva la vita\\n¿Dónde está el hombre con fuego en la sangre?\\nHe's been waiting around for the weekend\\nOK it's alright with me\\nSome things are just\\nRight about the time I missed your call\\nWhoa, whoa, whoa\\nI'm going down to the\\nI wanna hold em' like they do in texas please\\nWhatsoever I feared has\\nCome to life\"\n",
        "#print(\"Is english text?\", is_english(lyrics))'''\n",
        "\n",
        "lyrics = \"this a\\nthis a\\nthis ,  this\\nthis a gyal yah waan\\n( back it up )\\nthis thi thi ,  this\\nthis a gyal yah waan\\n( back it up )\\nthis a\\nthis a gyal yah\\nthis a gyal yah waan\\n ( back it up )\\nhey gyal !\"\n",
        "print(\"Is english text?\", is_english(lyrics))\n",
        "\n",
        "lyrics = \"flying\\nand you know i'm not coming down\\nyou are trying\\nbut you know you must soon go down\\nall my colours turn to cloud\\nall my colours turn to cloud\\n zimbo ,  zimbo ,  zimbo ,  zimbo ,  zimbo\\n zimbo ,  zimbo ,  zimbo ,  zimbo ,  zimbo\\n zimbo ,  zimbo ,  zimbo ,  zimbo ,  zimbo\\nzimbo ,  zimbo ,  zimbo ,  zimbo ,  zimbo\\nwhat to say\\nwhen your heart's in pieces ?\\nhow to play\"\n",
        "print(\"Is english text?\", is_english(lyrics))\n",
        "\n",
        "lyrics = \"intro :\\nkid's voice :\\nwise ... wise .... blessed ... blessed ...\\nmore fire !  !  ... more fire !  !  .... red\\ncapleton :\\nmore fire !  !  !  red hot !  !  !  !  yuh see ah now well done ,  yo !  !\\nlight up di fire from mi ready fi put it pon dem\\nhey gimme di hey gimme di yo !  !  !  !\\nchorus :\\ndat one yah name cuyah cuyah cuyah when dem see mi wid di fire\\ncuyah cuyah cuyah when mi bun di vampire\\ncuyah cuyah cuyah when mi bun di obeah wuker\\ntell dem cuyah !  !  !  ... cuyah !  !  !  ... cuyah !  !  !  ... again\"\n",
        "print(\"Is english text?\", is_english(lyrics))\n",
        "\n",
        "lyrics = \"so sick of playing these games ,  it's\\nimpossible for me to ever ever be happy ,  yeah\\nand i'm so sick of doing the same shit\\ni just wanna sleep a tad bit ,  more\\nmore ,  more ,  more\\n\\ni don't want to die\\ni'm in a elevator with snoop dogg and i just got a contact high\\nso everything better except the cheddar except when\\ni  start to close my eyes ,  or did i already close my eyes\" \n",
        "print(\"Is english text?\", is_english(lyrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  hi\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Is english text? True\n",
            "Language:  pt\n",
            "Language:  pt\n",
            "Language:  pt\n",
            "Is english text? False\n",
            "Language:  en\n",
            "Language:  ms\n",
            "Language:  en\n",
            "Language:  it\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  ms\n",
            "Is english text? False\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Language:  en\n",
            "Is english text? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3QHz7D3YsVv"
      },
      "source": [
        "Define lyrics preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU3aqPwFZeUm"
      },
      "source": [
        "blacklisted_chars  = { '\"', '“', '”', '<', '>', '@', '+', '|', '', '_', '·', '~', '#' }\n",
        "apostrophes        = { \"'\", '`', '’', '‘', '´' }\n",
        "dashes             = { '-', '‑', '–', '—', '−' }\n",
        "punctuation_subset = { ',' , ';', ':', '!', '?', ')', '}', '[', ']', '$', '/', '…', '\\n' }\n",
        "string_ending_chars = blacklisted_chars.union(dashes).union(punctuation_subset).union({'.'})\n",
        "dot_contractions = [\".\", \"mr\", \"mrs\", \"ms\", \"dr\", \"st\", \"prof\"]\n",
        "\n",
        "# USE A WHITELIST INSTEAD OF A BLACKLIST\n",
        "#whitelisted_chars = {  }\n",
        "\n",
        "#print(\"string_ending_chars: \", string_ending_chars)\n",
        "\n",
        "\n",
        "# Lyrics preprocessing.\n",
        "# Convert text to lower case letters to reduce the word's space.\n",
        "# Dataset does not include punctuation except contractions such as i'm, it's, isn't, ... and few uncleaned chars,\n",
        "# so remove these and replace contractions not in the vocabulary with the corresponding complete forms\n",
        "def lyrics_preprocessing(text):\n",
        "  #print(\"*\"*40)\n",
        "  #print(\"lyrics: \\n\", text)\n",
        "  #return text.lower() # TEST RAPIDO\n",
        "\n",
        "  debug = False\n",
        "  #if \"weren't\" in text.lower() or \"mustn't\" in text.lower() or \"shouldn't\" in text.lower():\n",
        "  #if \"'ve\" in text.lower():\n",
        "  #if \"'twas\" in text.lower():\n",
        "  #if \"pain'll\" in text.lower() or \"box'll\" in text.lower():\n",
        "  #if \"'\\\"ve\" in text:\n",
        "  #if \"forty-four lies\" in text.lower() or \"before i fall away\" in text.lower():\n",
        "  #if \"votin''\" in text:\n",
        "  #  debug = True\n",
        "\n",
        "  if not is_english(text):\n",
        "    return None\n",
        "\n",
        "\n",
        "  # Get the char at position i in the text if exists, otherwise return the empty char\n",
        "  def get_char(text, i):\n",
        "    try:\n",
        "      char = text[i]\n",
        "    except:\n",
        "      char = ''\n",
        "\n",
        "    return char\n",
        "\n",
        "  # Return true if char is an allowed space (\" \" or \"\\n\")\n",
        "  def is_allowed_space(char):\n",
        "    #print(\"is allowed space? \", char == ' ' or char == '\\n')\n",
        "    return char == ' ' or char == '\\n'\n",
        "\n",
        "  # Return true if char is a string ending (i.e. there is not a subsequent char or this is a whitespace or this is a double quotes)\n",
        "  def is_string_ending(char):\n",
        "    if debug:\n",
        "      print(\"char: \", char)\n",
        "      print(\"is char ending? \", not char or char.isspace() or char in string_ending_chars) # {'\"', ',', '.', ';', ':', '!', '?', '-', '(', ')', '{', '}', '[', ']', '…'}) #, \"'\"})\n",
        "    return not char or char.isspace() or char in string_ending_chars # {'\"', ',', '.', ';', ':', '!', '?', '-', '(', ')', '{', '}', '[', ']', '…'}\n",
        "\n",
        "  # Return true if the char at position i in the text is a string ending, otherwise false\n",
        "  def __is_string_ending(text, i):\n",
        "    next_char = get_char(text, i+1)\n",
        "    if debug:\n",
        "      print(\"Current char: \", text[i])\n",
        "      print(\"Next char: \", next_char)\n",
        "    return is_string_ending(next_char)\n",
        "\n",
        "  def match_next_chars_regex(text, i, regex, regex_len):\n",
        "    #print(\"Regex to match: \", regex)\n",
        "    try:\n",
        "      next_chars = text[i+1:i+1+regex_len]\n",
        "      #print(\"Text next_chars: \", next_chars)\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "    return True if re.match(regex, next_chars) else False\n",
        "\n",
        "  def match_prev_chars_regex(text, i, regex, regex_len):\n",
        "    #print(\"Regex to match: \", regex)\n",
        "    try:\n",
        "      prev_chars = text[i-regex_len:i]\n",
        "      #print(\"Text prev_chars: \", prev_chars)\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "    return True if re.match(regex, prev_chars) else False\n",
        "\n",
        "  # Takes in input a list of strings or a string.\n",
        "  # If string_ending parameter is false, return true if the next chars of the text match the word, otherwise false.\n",
        "  # If string_ending parameter is true, return true if the next chars of the text match the word and such chars are a word ending in the text, otherwise false\n",
        "  def match_next_chars(text, i, input, string_ending=False):\n",
        "    def __match(word):\n",
        "      if debug:\n",
        "        #print(\"Next chars of the text: \", text[i:])\n",
        "        print(\"word to match: \", word)\n",
        "      try:\n",
        "        next_chars = text[i+1:i+1+len(word)]\n",
        "        if debug:\n",
        "          print(\"text next_chars: \", next_chars)\n",
        "      except:\n",
        "        return False\n",
        "\n",
        "      if debug:\n",
        "        print(\"next_chars == word? \", next_chars.lower() == word)\n",
        "\n",
        "      if string_ending and not __is_string_ending(text, i+len(word)):\n",
        "        return False\n",
        "\n",
        "      return next_chars.lower() == word\n",
        " \n",
        "\n",
        "    # Check if input is a list of words\n",
        "    if isinstance(input, list):\n",
        "      # Iterate the words\n",
        "      for word in input:\n",
        "        if __match(word):\n",
        "          return True\n",
        "    elif isinstance(input, str):\n",
        "      return __match(input)\n",
        "    \n",
        "    return False\n",
        "\n",
        "    \n",
        "    '''if debug:\n",
        "      #print(\"Next chars of the text: \", text[i:])\n",
        "      print(\"word to match: \", word)\n",
        "    try:\n",
        "      next_chars = text[i+1:i+1+len(word)]\n",
        "      if debug:\n",
        "        print(\"text next_chars: \", next_chars)\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "    if debug:\n",
        "      print(\"next_chars == word? \", next_chars == word)\n",
        "\n",
        "    if next_chars.lower() != word:\n",
        "      return False\n",
        "\n",
        "    if string_ending:\n",
        "      return __is_string_ending(text, i+len(word))\n",
        "\n",
        "    return True #next_chars.lower() == word'''\n",
        "\n",
        "\n",
        "  # Takes in input a list of strings or a string.\n",
        "  # If string_ending and string_beginning parameters are false, return true if the prev chars of the text match the word, otherwise false.\n",
        "  # If string_ending parameter is true, return true if the prev chars of the text match the word and such chars are a word ending in the text, otherwise false.\n",
        "  # If string_beginning parameter is true, return true if the prev chars of the text match the word and such chars are a word beginning in the text, otherwise false.\n",
        "  def match_prev_chars(text, i, input, string_ending=False, string_beginning=False):\n",
        "    def __match(word):\n",
        "      if debug:\n",
        "        #print(\"Last chars of the text: \", text[:i])\n",
        "        print(\"word to match: \", word)\n",
        "\n",
        "      if string_ending and not __is_string_ending(text, i):\n",
        "        return False\n",
        "\n",
        "      if string_beginning:\n",
        "        char = get_char(text, i-len(word)-1)\n",
        "        if not is_string_ending(char):\n",
        "          return False\n",
        "\n",
        "      try:\n",
        "        prev_chars = text[i-len(word):i]\n",
        "        if debug:\n",
        "          print(\"text prev_chars: \", prev_chars)\n",
        "      except:\n",
        "        return False\n",
        "\n",
        "      return prev_chars.lower() == word\n",
        "\n",
        "\n",
        "    # Check if input is a list of words\n",
        "    if isinstance(input, list):\n",
        "      # Iterate the words\n",
        "      for word in input:\n",
        "        if __match(word):\n",
        "          return True\n",
        "    elif isinstance(input, str):\n",
        "      return __match(input)\n",
        "    \n",
        "    return False\n",
        "\n",
        "\n",
        "    '''if debug:\n",
        "      #print(\"Last chars of the text: \", text[:i])\n",
        "      print(\"word to match: \", word)\n",
        "    try:\n",
        "      prev_chars = text[i-len(word):i]\n",
        "      if debug:\n",
        "        print(\"text prev_chars: \", prev_chars)\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "    if prev_chars.lower() != word:\n",
        "      return False\n",
        "\n",
        "    if string_ending:\n",
        "      return __is_string_ending(text, i)\n",
        "    \n",
        "    return True'''\n",
        "\n",
        "\n",
        "\n",
        "  def check_prev_chars(text, i, words):\n",
        "    for word in words:\n",
        "      if debug:\n",
        "        print(\"Check prev chars of word: \", word)\n",
        "      match = True\n",
        "      word_len = len(word)\n",
        "      \n",
        "      for j in range(word_len):\n",
        "        prev_char_text = get_char(text, i-j-1)\n",
        "        prev_char_word = get_char(word, word_len-j-1)\n",
        "        if debug:\n",
        "          print(\"Check if text char %c == word char %c\" %(prev_char_text, prev_char_word))\n",
        "\n",
        "        if prev_char_text != prev_char_word:\n",
        "          match = False\n",
        "          break\n",
        "\n",
        "      if match and word_len > 0:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "  def analyze_apostrophe(text, i, out_text):\n",
        "    # Try to get the next char\n",
        "    next_char = get_char(text, i+1).lower()\n",
        "    if debug:\n",
        "      print(\"=\"*20)\n",
        "      print(\"char after apostrophe is: \", next_char)\n",
        "\n",
        "    skip_char = 0\n",
        "    is_contraction = True\n",
        "\n",
        "    # Check if the apostrophe is a contraction of an 'ing' ending (e.g., cryin' -> crying)\n",
        "    if match_prev_chars(text, i, \"in\", string_ending=True):\n",
        "      # Replace the apostrophe with a 'g'\n",
        "      out_text += \"g\"\n",
        "    \n",
        "\n",
        "    # Else check if the apostrophe is a contraction of a decade (e.g., 60', 60's, 1960's -> 60s)\n",
        "    #elif i >= 2 and re.match(\"^[0-9]+$\", text[i-2:i]):\n",
        "    #  out_text += \"s\"\n",
        "\n",
        "    #  # If the next char is a 's', skip it\n",
        "    #  if next_char == 's':\n",
        "    #    skip_char = 1\n",
        "\n",
        "    # Else add the apostrophe (') to the output text\n",
        "    #else:\n",
        "    #  out_text += \"'\"\n",
        "\n",
        "\n",
        "    # Else check if the apostrophe is followed by \"ve\"\n",
        "    elif match_next_chars(text, i, \"ve\", string_ending=True):\n",
        "      #print(\"'ve found\")\n",
        "      # Check if \"'ve\" follows a word in the list (s.t. the word + 've is not in the vocabulary)\n",
        "      '''match = check_prev_chars(out_text, len(out_text), [\"i\", \"should\", \"must\", \"might\", \"could\", \"would\", \"who\", \"that\"])\n",
        "      if match:\n",
        "        if debug:\n",
        "          print(\"Match found\")\n",
        "        # If a match is found, replace the contraction with the complete form (word + \" have\")\n",
        "        skip_char = 2\n",
        "        out_text += \" have\"\n",
        "      else:\n",
        "        out_text += \"'\"'''\n",
        "\n",
        "      # Check if \"'ve\" follows a word in the list (s.t. the word + 've is not in the vocabulary)\n",
        "      match = check_prev_chars(out_text, len(out_text), [\"l\"])\n",
        "      if match:\n",
        "        # Replace \"l've\" with \"love\"\n",
        "        skip_char = 2\n",
        "        out_text += \"ove\"\n",
        "      else: \n",
        "        # Else replace the contraction with the complete form (word + \" have\")\n",
        "        # COSÌ SOSTITUIAMO ANCHE ABBREVIAZIONI CON 're CHE SONO PRESENTI NEL FILE word2vec (POCO IMPORTA).\n",
        "        skip_char = 2\n",
        "        out_text += \" have\"\n",
        "\n",
        "    # Else check if the apostrophe is followed by \"re\" or \"r\"         \n",
        "    elif match_next_chars(text, i, \"re\", string_ending=True):\n",
        "      '''#print(\"'re found\")\n",
        "      # Check if \"'re\" follows a word in the list (s.t. the word + 're is not in the vocabulary)\n",
        "      match = check_prev_chars(out_text, len(out_text), [\"why\"])\n",
        "      if match:\n",
        "        if debug:\n",
        "          print(\"Replace 're with are\")\n",
        "        # If a match is found, replace the contraction with the complete form (word + \" are\")\n",
        "        skip_char = 2\n",
        "        out_text += \" are\"\n",
        "      else:\n",
        "        out_text += \"'\"'''\n",
        "      \n",
        "      # COSÌ SOSTITUIAMO ANCHE ABBREVIAZIONI CON 're CHE SONO PRESENTI NEL FILE word2vec (POCO IMPORTA).\n",
        "      # PER EVITARLO ANDREBBE VERIFICATO CHE I CARATTERI PRECEDENTI L'APOSTROFO NON SIANO PAROLE LE CUI ABBREVIAZIONI SONO GIÀ PRESENTI\n",
        "      # If a match is found, replace the contraction with the complete form (word + \" are\")\n",
        "      skip_char = 2\n",
        "      out_text += \" are\"\n",
        "\n",
        "    # Else check if the apostrophe is followed by \"r\"         \n",
        "    elif match_next_chars(text, i, \"r\", string_ending=True):\n",
        "      # If a match is found, replace the contraction with the complete form (word + \" are\")\n",
        "      skip_char = 1\n",
        "      out_text += \" are\"\n",
        "\n",
        "    # Else check if the apostrophe is followed by \"ll\"\n",
        "    elif match_next_chars(text, i, \"ll\", string_ending=True):\n",
        "      #print(\"'ll found\")\n",
        "      # Check if \"'ll\" follows a word in the list (s.t. the word + 'll is not in the vocabulary)\n",
        "      match = check_prev_chars(out_text, len(out_text), [\"ya\"])\n",
        "      if match:\n",
        "        if debug:\n",
        "          print(\"Replace 'll with ou all\")\n",
        "        # If a match is found, replace the contraction with the complete form (word + \" ou all\")\n",
        "        skip_char = 2\n",
        "        out_text = out_text[:len(out_text)-1] + \"ou all\"\n",
        "      else:\n",
        "        # COSÌ SOSTITUIAMO ANCHE ABBREVIAZIONI CON 'll CHE SONO PRESENTI NEL FILE word2vec (POCO IMPORTA)\n",
        "        if debug:\n",
        "          print(\"Replace 'll with will\")\n",
        "        # Else replace the contraction with the complete form (word + \" will\")\n",
        "        skip_char = 2\n",
        "        out_text += \" will\"\n",
        "\n",
        "    # Else add the apostrophe (') to the output text\n",
        "    else:\n",
        "      # Check if the apostrophe does not follow another one\n",
        "      #if not check_prev_chars(out_text, len(out_text), [\"'\"]):\n",
        "      #  out_text += \"'\"\n",
        "\n",
        "      # Check if the apostrophe follows another one (e.g. votin'', i''ve)\n",
        "      if check_prev_chars(out_text, len(out_text), [\"'\"]):\n",
        "        # Perform the analysis of the apostrophe (removing from the output the apostrophe itself).\n",
        "\n",
        "        # Try with contraction of subsequent chars (e.g. ve, re, ll)\n",
        "        out_text, skip_char, is_contraction = analyze_apostrophe(text, i, out_text[:len(out_text)-1])\n",
        "        if debug:\n",
        "          print(\"is ' for subsequent chars a contraction? \", is_contraction)\n",
        "        if is_contraction:\n",
        "          return out_text, skip_char, is_contraction\n",
        "\n",
        "        # Replace current apostrophe in the text to analyze previous chars (to recognize an eventual string ending)\n",
        "        text = text[:i] + \" \" + text[i+1:]\n",
        "\n",
        "        # Try with contraction of previous chars (e.g. \"ing\" ending)\n",
        "        out_text, skip_char, is_contraction = analyze_apostrophe(text, i-1, out_text[:len(out_text)-1])\n",
        "        if debug:\n",
        "          print(\"is ' for previous chars a contraction? \", is_contraction)\n",
        "      else:\n",
        "        out_text += \"'\"\n",
        "        is_contraction = False\n",
        "\n",
        "    return out_text, skip_char, is_contraction\n",
        "\n",
        "  \n",
        "  skip_char = 0\n",
        "  out_text = \"\"\n",
        "\n",
        "  # Iterate char of the input lyrics\n",
        "  for i in range(len(text)):\n",
        "    # Check if the current char has to be skipped\n",
        "    if skip_char > 0:\n",
        "      skip_char -= 1\n",
        "      continue\n",
        "\n",
        "    # Get the current char\n",
        "    char = text[i]\n",
        "\n",
        "    if debug:\n",
        "      print(\"=\"*20)\n",
        "      print(\"current char is: \", char)\n",
        "\n",
        "    # Remove chars in the blacklist\n",
        "    if char not in blacklisted_chars:\n",
        "      # Check if the char is a non-allowed space (i.e. \\t, \\v, \\f, \\r, etc.) or a dash\n",
        "      if (char.isspace() and not is_allowed_space(char)) or char in dashes:\n",
        "        if debug:\n",
        "          print(\"Replace it with a whitespace\")\n",
        "        # Replace it with a whitespace\n",
        "        out_text += ' '\n",
        "\n",
        "      # Check if the char is an apostrophe (i.e. ',`,’, etc.)\n",
        "      elif char in apostrophes:\n",
        "        # Try to get the next char\n",
        "        next_char = get_char(text, i+1).lower()\n",
        "        if debug:\n",
        "          print(\"=\"*20)\n",
        "          print(\"char after apostrophe is: \", next_char)\n",
        "\n",
        "        out_text, skip_char, _ = analyze_apostrophe(text, i, out_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        '''elif match_next_chars(text, i, \"ll\", True):\n",
        "          #print(\"'ll found\")\n",
        "          # Check if \"'ll\" follows one word in the list (s.t. the word + 'll is not in the vocabulary)\n",
        "          match = check_prev_chars(out_text, len(out_text), [\"i\", \"he\", \"she\", \"it\", \"who\", \"there\", \"that\", \"what\", \"this\"])\n",
        "          if match:\n",
        "            if debug:\n",
        "              print(\"Match found\")\n",
        "            # If a match is found, replace the contraction with the complete form (word + \" ou all\")\n",
        "            skip_char = 2\n",
        "            out_text += \" will\"\n",
        "          elif check_prev_chars(out_text, len(out_text), [\"ya\"]):\n",
        "            # If a match is found, replace the contraction with the complete form (word + \"ou all\")\n",
        "            skip_char = 2\n",
        "            out_text = out_text[:len(out_text)-1] + \"ou all\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "        elif match_next_chars(text, i, \"all\", True):\n",
        "          #print(\"'all found\")\n",
        "          # Check if \"'all\" follows one word in the list (s.t. the word + 'all is not in the vocabulary)\n",
        "          match = check_prev_chars(out_text, len(out_text), [\"y\"])\n",
        "          if match:\n",
        "            if debug:\n",
        "              print(\"Match found\")\n",
        "            # If a match is found, replace the contraction with the complete form (word + \" ou all\")\n",
        "            skip_char = 3\n",
        "            out_text += \"ou all\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "        elif match_next_chars(text, i, \"d\", True):\n",
        "          #print(\"'d found\")\n",
        "          # Check if \"'d\" follows one word in the list (s.t. the word + 'd is not in the vocabulary)\n",
        "          match = check_prev_chars(out_text, len(out_text), [\"what\", \"where\", \"why\"])\n",
        "          if match:\n",
        "            if debug:\n",
        "              print(\"Match found\")\n",
        "            # If a match is found, replace the contraction with the complete form (word + \" did\")\n",
        "            skip_char = 1\n",
        "            out_text += \" did\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "        elif match_next_chars(text, i, \"s\", True):\n",
        "          #print(\"'s found\")\n",
        "          # Check if \"'s\" follows one word in the list (s.t. the word + 's is not in the vocabulary)\n",
        "          match = check_prev_chars(out_text, len(out_text), [\"everything\", \"everyone\", \"here\", \"now\", \"body\", \"number\", \"back\", \"time\", \"rain\", \"whatever\"])\n",
        "          if match:\n",
        "            if debug:\n",
        "              print(\"Match found\")\n",
        "            # If a match is found, replace the contraction with the complete form (word + \" is\")\n",
        "            skip_char = 1\n",
        "            out_text += \" is\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "        elif match_next_chars(text, i, \"t\", True):\n",
        "          # Try to get the previous char\n",
        "          prev_char = get_char(out_text, len(out_text)-1)\n",
        "          \n",
        "          if debug:\n",
        "            print(\"char before 't  is: \", prev_char)\n",
        "            print(\"char before 't in out_text is: \", out_text[i-1])\n",
        "            print(\"i:\", i)\n",
        "            print(\"len out_text: \", len(out_text))\n",
        "\n",
        "          # Check if the char before the apostrophe is 'n' (for n't)\n",
        "          if prev_char == 'n':\n",
        "            if debug:\n",
        "              print(\"Found n't in the text\")\n",
        "            # Check if n't follows one of the words s.t. the word + n't is not in the vocabulary\n",
        "            match = check_prev_chars(out_text, len(out_text)-1, [\"were\", \"had\", \"must\", \"should\"])\n",
        "\n",
        "            if match:\n",
        "              if debug:\n",
        "                print(\"Match found\")\n",
        "              # If a match is found, replace the contraction with the complete form (word + \" not\")\n",
        "              skip_char = 1\n",
        "              # Use len of out_text instead of i because after a replacement, i in the original text and in the out_text can refer to different chars\n",
        "              out_text = out_text[:len(out_text)-1] + \" not\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "\n",
        "        elif is_string_ending(get_char(out_text, len(out_text)-1)):\n",
        "          #(\"'twas\", \"it was\")\n",
        "          #(\"'cept\", \"except\")\n",
        "          #(\"'ceptin\", \"except\")\n",
        "          #(\"'cross\", \"across\")\n",
        "          #(\"'scuse\", \"scuse\")\n",
        "          #(\"'neath\", \"beneath\")\n",
        "          if match_next_chars(text, i, \"twas\", True):\n",
        "            skip_char = 4\n",
        "            out_text += \"it was\"\n",
        "          elif match_next_chars(text, i, \"cept\", True):\n",
        "            skip_char = 4\n",
        "            out_text += \"except\"\n",
        "          elif match_next_chars(text, i, \"ceptin\", True):\n",
        "            skip_char = 6\n",
        "            out_text += \"except\"\n",
        "          elif match_next_chars(text, i, \"cross\", True):\n",
        "            skip_char = 5\n",
        "            out_text += \"across\"\n",
        "          elif match_next_chars(text, i, \"scuse\", True):\n",
        "            skip_char = 5\n",
        "            out_text += \"scuse\"\n",
        "          elif match_next_chars(text, i, \"neath\", True):\n",
        "            skip_char = 5\n",
        "            out_text += \"beneath\"\n",
        "\n",
        "\n",
        "        # Else add the apostrophe (') to the output text\n",
        "        else:\n",
        "          out_text += \"'\"'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Else check if the apostrophe is a contraction of 'have' (e.g., i've -> i have)\n",
        "        '''elif next_char == 'v':\n",
        "          # Try to get the char after the 'v'\n",
        "          next_char = get_char(text, i+2)\n",
        "          if debug:\n",
        "            print(\"out_text so far:\", out_text)\n",
        "            print(\"char after 'v is: \", next_char)\n",
        "\n",
        "          if next_char == 'e':\n",
        "            # Try to get the char after the 'e'\n",
        "            next_char = get_char(text, i+3)\n",
        "            if debug:\n",
        "              print(\"char after 've is: \", next_char)\n",
        "            \n",
        "            # Check if 'e' is the last character of the string (i.e. there is not a subsequent char or this is a whitespace)\n",
        "            if not next_char or next_char == ' ':\n",
        "              if debug:\n",
        "                print(\"Found 've in the text\")\n",
        "              # Check if \"'ve\" follows one word in the list (s.t. the word + 've is not in the vocabulary)\n",
        "              match = check_prev_chars(out_text, len(out_text), [\"i\", \"should\", \"must\", \"might\", \"could\", \"would\", \"who\", \"that\"])\n",
        "              if match:\n",
        "                if debug:\n",
        "                  print(\"Match found\")\n",
        "                # If a match is found, replace the contraction with the complete form (word + \" have\")\n",
        "                skip_char = 2\n",
        "                out_text += \" have\"\n",
        "              else:\n",
        "                out_text += \"'\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "\n",
        "        # Else check if the apostrophe is a contraction of 'are' (e.g., why're -> why are)\n",
        "        elif next_char == 'r':\n",
        "          # Try to get the char after the 'r'\n",
        "          next_char = get_char(text, i+2)\n",
        "\n",
        "          if next_char == 'e':\n",
        "            # Try to get the char after the 'e'\n",
        "            next_char = get_char(text, i+3)\n",
        "            \n",
        "            # Check if 'e' is the last character of the string (i.e. there is not a subsequent char or this is a whitespace)\n",
        "            if not next_char or next_char == ' ':\n",
        "              # Check if \"'re\" follows one word in the list (s.t. the word + 're is not in the vocabulary)\n",
        "              match = check_prev_chars(out_text, len(out_text), [\"why\"])\n",
        "              if match:\n",
        "                # If a match is found, replace the contraction with the complete form (word + \" are\")\n",
        "                skip_char = 2\n",
        "                out_text += \" are\"\n",
        "              else:\n",
        "                out_text += \"'\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "\n",
        "        # Else check if the apostrophe is a contraction of 'will' (e.g., i'll -> i will)\n",
        "        elif next_char == 'l':\n",
        "          # Try to get the char after the 'l'\n",
        "          next_char = get_char(text, i+2)\n",
        "\n",
        "          if next_char == 'l':\n",
        "            # Try to get the char after the 'l'\n",
        "            next_char = get_char(text, i+3)\n",
        "            \n",
        "            # Check if 'l' is the last character of the string (i.e. there is not a subsequent char or this is a whitespace)\n",
        "            if not next_char or next_char == ' ':\n",
        "              # Check if \"'ll\" follows one word in the list (s.t. the word + 'll is not in the vocabulary)\n",
        "              match = check_prev_chars(out_text, len(out_text), [\"i\", \"he\", \"she\", \"it\", \"who\", \"there\", \"that\", \"what\", \"this\"])\n",
        "              if match:\n",
        "                # If a match is found, replace the contraction with the complete form (word + \" will\")\n",
        "                skip_char = 2\n",
        "                out_text += \" will\"\n",
        "              elif check_prev_chars(out_text, len(out_text), [\"ya\"]):\n",
        "                # If a match is found, replace the contraction with the complete form (word + \"ou all\")\n",
        "                skip_char = 2\n",
        "                out_text = out_text[:len(out_text)-1] + \"ou all\"\n",
        "              else:\n",
        "                out_text += \"'\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "        \n",
        "        # Check if the next char to the apostrophe is 't' (for n't)\n",
        "        elif next_char == 't':\n",
        "          # Try to get the next char to 't'\n",
        "          next_char = get_char(text, i+2)\n",
        "\n",
        "          if debug:\n",
        "            print(\"out_text so far:\", out_text)\n",
        "            print(\"char after 't is: \", next_char)\n",
        "\n",
        "          # If there is not a subsequent char or this is a whitespace\n",
        "          if not next_char or next_char == ' ':\n",
        "            # Try to get the previous char\n",
        "            prev_char = get_char(out_text, len(out_text)-1)\n",
        "            \n",
        "            if debug:\n",
        "              print(\"char before 't  is: \", prev_char)\n",
        "              print(\"char before 't in out_text is: \", out_text[i-1])\n",
        "              print(\"i:\", i)\n",
        "              print(\"len out_text: \", len(out_text))\n",
        "\n",
        "            # Check if the char before the apostrophe is 'n' (for n't)\n",
        "            if prev_char == 'n':\n",
        "              if debug:\n",
        "                print(\"Found n't in the text\")\n",
        "              # Check if n't follows one of the words s.t. the word + n't is not in the vocabulary\n",
        "              match = check_prev_chars(out_text, len(out_text)-1, [\"were\", \"had\", \"must\", \"should\"])\n",
        "\n",
        "              if match:\n",
        "                if debug:\n",
        "                  print(\"Match found\")\n",
        "                # If a match is found, replace the contraction with the complete form (word + \" not\")\n",
        "                skip_char = 1\n",
        "                # Use len of out_text instead of i because after a replacement, i in the original text and in the out_text can refer to different chars\n",
        "                out_text = out_text[:len(out_text)-1] + \" not\"\n",
        "              else:\n",
        "                out_text += \"'\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "\n",
        "        # Check 'd\n",
        "        elif next_char == 'd':\n",
        "          # Try to get the char after the 'd'\n",
        "          next_char = get_char(text, i+2)\n",
        "\n",
        "          # If there is not a subsequent char or this is a whitespace\n",
        "          if not next_char or next_char == ' ':\n",
        "            # Check if 'd follows one of the words s.t. the word + 'd is not in the vocabulary\n",
        "            match = check_prev_chars(out_text, len(out_text), [\"what\", \"where\", \"why\"])\n",
        "            if match:\n",
        "              # If a match is found, replace the contraction with the complete form (word + \" will\")\n",
        "              skip_char = 1\n",
        "              out_text += \" did\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "        # Check 's\n",
        "        elif next_char == 's':\n",
        "          # Try to get the char after the 's'\n",
        "          next_char = get_char(text, i+2)\n",
        "\n",
        "          # If there is not a subsequent char or this is a whitespace\n",
        "          if not next_char or next_char == ' ':\n",
        "            # Check if 's follows one of the words s.t. the word + 's is not in the vocabulary\n",
        "            match = check_prev_chars(out_text, len(out_text), [\"everything\", \"everyone\", \"here\", \"now\", \"body\", \"number\", \"back\", \"time\", \"rain\", \"whatever\"])\n",
        "            if match:\n",
        "              # If a match is found, replace the contraction with the complete form (word + \" will\")\n",
        "              skip_char = 1\n",
        "              out_text += \" is\"\n",
        "            else:\n",
        "              out_text += \"'\"\n",
        "          else:\n",
        "            out_text += \"'\"\n",
        "\n",
        "\n",
        "        # Else add the apostrophe (') to the output text\n",
        "        else:\n",
        "          out_text += \"'\"'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # Else check if the char is a number\n",
        "      elif re.match(\"^[0-9]$\", char):\n",
        "        #print(\"=\"*40)\n",
        "        #print(\"Current char is a number: \", char)\n",
        "        is_repetition = False\n",
        "        is_decade     = False\n",
        "        j = 0\n",
        "        next_char = char\n",
        "\n",
        "        # Iterate the string\n",
        "        while not is_string_ending(next_char):\n",
        "          # Try to get the next char\n",
        "          next_char = get_char(text, i+j+1)\n",
        "          #print(\"=\"*40)\n",
        "          #print(\"Number next_char: \", next_char)\n",
        "\n",
        "          # Check if the text is ended\n",
        "          if not next_char:\n",
        "            break\n",
        "\n",
        "          # Advance the offset to the current char\n",
        "          j += 1\n",
        "      \n",
        "          # Check if the number is followed by 'x' (repetition in the lyrics: e.g., '2x', '10x' -> skip it)\n",
        "          if next_char.lower() == 'x' or next_char == '×':\n",
        "            is_repetition = True\n",
        "\n",
        "          # Else check if the number is followed by an apostrophe\n",
        "          elif next_char == \"'\":\n",
        "            # Check if this is a contraction of a decade (e.g., 60', 60's, 1960's)\n",
        "            if j == 2 or j == 4:\n",
        "              # Try to get the char next to the apostrophe.\n",
        "              next_char = get_char(text, i+j+1)\n",
        "\n",
        "              # Check if the char next to the apostrophe does not exist (i.e. the text is ended), is a 's' or a string ending\n",
        "              if is_string_ending(char) or next_char.lower() == 's':\n",
        "                is_decade = True\n",
        "\n",
        "            # In any case break the loop and if the number is not a contraction of a decade, the apostrophe will be evaluated in the next iteration.\n",
        "            # Don't skip the apostrophe (for the moment) to not include it in the out_text\n",
        "            #j -= 1\n",
        "            break\n",
        "\n",
        "        # Set the chars to skip\n",
        "        #skip_char = j\n",
        "        skip_char = j-1\n",
        "\n",
        "        # Check if the number is not a repetition\n",
        "        if not is_repetition:\n",
        "          # Try to include the subsequent whitespace if exists\n",
        "          #try:\n",
        "          #  substr = text[i:i+j+1]  \n",
        "          #except:\n",
        "          #  substr = text[i:i+j]\n",
        "\n",
        "          substr = text[i:i+j]\n",
        "          out_text += substr.lower()\n",
        "\n",
        "          # Check if the number is a decade\n",
        "          if is_decade: \n",
        "            # Try to get the char next to the apostrophe.\n",
        "            # text[i+j+1] is the apostrophe because we performed j -= 1 to not include it in the out_text\n",
        "            #next_char = get_char(text, i+j+2)                 \n",
        "\n",
        "            # If the next char is a 's', skip the apostrophe and it\n",
        "            if next_char == 's':\n",
        "              skip_char += 2\n",
        "            # Else skip only the apostrophe\n",
        "            else:\n",
        "              skip_char += 1\n",
        "\n",
        "            out_text += \"s\"\n",
        "\n",
        "      # Else check if the char is 'x' or '×'\n",
        "      elif char.lower() == 'x' or char == '×':\n",
        "        is_repetition = False\n",
        "        j = 0\n",
        "        next_char = char\n",
        "\n",
        "        # Iterate the string\n",
        "        while not is_string_ending(next_char):\n",
        "          # Try to get the next char\n",
        "          next_char = get_char(text, i+1+j)\n",
        "\n",
        "          # Check if the text is ended\n",
        "          if not next_char:\n",
        "              break\n",
        "  \n",
        "          # Advance the offset to the current char\n",
        "          j += 1\n",
        "\n",
        "          # Check if the 'x' is followed by a number (i.e. repetition in the lyrics: e.g., 'x2', 'x10' -> skip it)\n",
        "          if re.match(\"^[0-9]$\", next_char):\n",
        "            is_repetition = True\n",
        "          else:\n",
        "            break\n",
        "\n",
        "        # Set the chars to skip\n",
        "        skip_char = j-1 #j\n",
        "\n",
        "        # Check if the number is not a repetition\n",
        "        if not is_repetition:\n",
        "          # Try to include the subsequent whitespace if exists\n",
        "          #try:\n",
        "          #  substr = text[i:i+j+1]  \n",
        "          #except:\n",
        "          #  substr = text[i:i+j]\n",
        "\n",
        "          substr = text[i:i+j]\n",
        "\n",
        "          out_text += substr.lower()\n",
        "\n",
        "      # Check if the char is a punctuation one (subset) or newline\n",
        "      elif char in punctuation_subset:\n",
        "        # Surround it with whitespaces to include it in the subsequent splitting of words (surround for avoiding missing whitespaces)\n",
        "        out_text += \" \" + char + \" \"\n",
        "\n",
        "      # Check if the char is a dot\n",
        "      elif char == '.':\n",
        "        #print(\"\\nCurrent char is a dot\")\n",
        "        # Check if \".\" belongs to an acronym (e.g. U.S.A., U.S.A)\n",
        "        '''if match_next_chars_regex(text, i, \"^[a-zA-Z]\\.$\", 2) or match_prev_chars_regex(text, i, \"^\\.[a-zA-Z]$\", 2):\n",
        "          #print(\"Acronym found\")\n",
        "          # Add the dot and the next char to the output\n",
        "          out_text += text[i:i+2]\n",
        "          skip_char = 1'''\n",
        "\n",
        "        # Check if \".\" belongs to an acronym (e.g. U.S.A., U.S.A)\n",
        "        if match_next_chars_regex(text, i, \"^[a-zA-Z]\\.$\", 2):\n",
        "          #print(\"Acronym found\")\n",
        "          # Add the dot and the next char to the output (replacing the previous character of the acronym with the original one, e.g. uppercase)\n",
        "          out_text = out_text[:len(out_text)-1] + text[i-1:i+2]\n",
        "          skip_char = 1\n",
        "\n",
        "        elif match_prev_chars_regex(text, i, \"^\\.[a-zA-Z]$\", 2):\n",
        "          #print(\"Acronym found\")\n",
        "          if match_next_chars_regex(text, i, \"^[a-zA-Z]$\", 1):\n",
        "            # Add the dot and the next char to the output\n",
        "            out_text += text[i:i+2]\n",
        "            skip_char = 1\n",
        "          else:\n",
        "            # Add the dot + whitespace\n",
        "            out_text += '. '\n",
        "\n",
        "        # The dot does not belong to an acronym\n",
        "        else:\n",
        "          #print(\"Acronym not found\")\n",
        "          # Check if \".\" follows a string in the list (i.e. multiple dots or contraction in which the dot must not be considered alone)\n",
        "          #if not check_prev_chars(out_text, len(out_text), dot_contractions):\n",
        "          if not match_prev_chars(out_text, len(out_text), dot_contractions, string_beginning=True):\n",
        "            # No, so add a whitespace to include it alone in the splitting of words \n",
        "            out_text += \" \"\n",
        "\n",
        "          # Add the dot in the output\n",
        "          out_text += char\n",
        "\n",
        "          # Check if \".\" precedes a whitespace (i.e. detect missing whitespace) or a dot (i.e. multiple dots)\n",
        "          if not match_next_chars(text, i, \" \", string_ending=False) and not match_next_chars(text, i, \".\", string_ending=False):\n",
        "            # No, so add a whitespace to include the next word in the splitting of words\n",
        "            out_text += \" \"\n",
        "\n",
        "      # Check if the char is \"(\"\n",
        "      elif char == '(':\n",
        "        # Check if the text in parenthesis is a repetition with 1 digit (e.g. (2x), (x2))\n",
        "        if match_next_chars_regex(text, i, \"^([0-9]+[xX×]|[xX×][0-9]+)\\)$\", 3):\n",
        "          skip_char = 3\n",
        "        # Check if the text in parenthesis is a repetition with 2 digits (e.g. (10x), (x10))\n",
        "        elif match_next_chars_regex(text, i, \"^([0-9]+[xX×]|[xX×][0-9]+)\\)$\", 4):\n",
        "          skip_char = 4\n",
        "        else:\n",
        "          # Surround it with whitespaces to include it in the subsequent splitting of words (surround for avoiding missing whitespaces)\n",
        "          out_text += \" \" + char + \" \"\n",
        "\n",
        "      # Check if the char is \"(\"\n",
        "      elif char == '{':\n",
        "        # Check if the text in parenthesis is a repetition with 1 digit (e.g. {2x}, {x2})\n",
        "        if match_next_chars_regex(text, i, \"^([0-9]+[xX×]|[xX×][0-9]+)\\}$\", 3):\n",
        "          skip_char = 3\n",
        "        # Check if the text in parenthesis is a repetition with 2 digits (e.g. {10x}, {x10})\n",
        "        elif match_next_chars_regex(text, i, \"^([0-9]+[xX×]|[xX×][0-9]+)\\}$\", 4):\n",
        "          skip_char = 4\n",
        "        else:\n",
        "          # Surround it with whitespaces to include it in the subsequent splitting of words (surround for avoiding missing whitespaces)\n",
        "          out_text += \" \" + char + \" \"\n",
        "\n",
        "      elif char == '*':\n",
        "        # Check if \"*\" precedes or follows a parenthesis\n",
        "        if match_prev_chars(text, i, [\"(\", \"[\", \"{\"], string_ending=False) or match_next_chars(text, i, [\")\", \"]\", \"}\"], string_ending=False):\n",
        "          continue\n",
        "        # Check if \"*\" follows a space or newline (probably is not really text, e.g. *drum solo*)\n",
        "        elif match_prev_chars(text, i, [\" \", \"\\n\"]):\n",
        "          # Replace with a parenthesis + whitespace\n",
        "          out_text += '( '\n",
        "        # Check if \"*\" precedes a string ending (probably is not really text, e.g. *drum solo*)\n",
        "        elif is_string_ending(get_char(text, i+1)):\n",
        "          # Replace with a whitespace + parenthesis\n",
        "          out_text += ' )'\n",
        "        else:\n",
        "          # Add the * to the output text\n",
        "          out_text += char\n",
        "\n",
        "      # Else add the lower case version of the char\n",
        "      else:\n",
        "        out_text += char.lower()\n",
        "\n",
        "    # Else this is a blacklisted char\n",
        "    else:\n",
        "      # Try to get the previous char\n",
        "      prev_char = get_char(out_text, len(out_text)-1)\n",
        "\n",
        "      if debug:\n",
        "        print(\"Char before the blacklisted char is: \", prev_char)\n",
        "        print(\"Text before the blacklisted char is: \", out_text)\n",
        "\n",
        "      # Check if the blacklisted char follows an apostrophe (e.g. i'\"ve, cryin'\")\n",
        "      if prev_char == \"'\":\n",
        "        # Perform the analysis of the apostrophe (removing from the output the apostrophe itself)\n",
        "        out_text, skip_char, _ = analyze_apostrophe(text, i, out_text[:len(out_text)-1])\n",
        "\n",
        "        # We don't need to check previous chars because blacklisted chars are included in string_ending_chars set (i.e. cryin'\" -> crying)\n",
        "        \n",
        "\n",
        "  # '90s '72 -> remove ' before number\n",
        "\n",
        "\n",
        "  # Replace contractions not in the vocabulary with corresponding complete forms\n",
        "  # HO INSERITO NEL CICLO SOPRA 've, 're, 'll, n't, 'd, 's  INVECE DI METTERLI QUI (6m E 6m, FORSE È PIÙ VELOCE replace)\n",
        "  # UPDATE: NEL CICLO SOPRA 've, 're, 'll, IL RESTO QUI\n",
        "  '''out_text = out_text.replace(\"i've\", \"i have\")\n",
        "  out_text = out_text.replace(\"should've\", \"should have\")\n",
        "  out_text = out_text.replace(\"must've\", \"must have\")\n",
        "  out_text = out_text.replace(\"might've\", \"might have\")\n",
        "  out_text = out_text.replace(\"could've\", \"could have\")\n",
        "  out_text = out_text.replace(\"would've\", \"would have\")\n",
        "  out_text = out_text.replace(\"who've\", \"who have\")\n",
        "  out_text = out_text.replace(\"that've\", \"that have\")\n",
        "  out_text = out_text.replace(\"when've\", \"when have\")\n",
        "\n",
        "  out_text = out_text.replace(\"why're\", \"why are\")\n",
        "\n",
        "  out_text = out_text.replace(\"i'll\", \"i will\")\n",
        "  out_text = out_text.replace(\"he'll\", \"he will\")\n",
        "  out_text = out_text.replace(\"she'll\", \"she will\")\n",
        "  out_text = out_text.replace(\"it'll\", \"it will\")\n",
        "  out_text = out_text.replace(\"who'll\", \"who will\")\n",
        "  out_text = out_text.replace(\"there'll\", \"there will\")\n",
        "  out_text = out_text.replace(\"that'll\", \"that will\")\n",
        "  out_text = out_text.replace(\"what'll\", \"what will\")\n",
        "  out_text = out_text.replace(\"this'll\", \"this will\")'''\n",
        "\n",
        "  out_text = out_text.replace(\"y'all\", \"you all\")\n",
        "  #out_text = out_text.replace(\"ya'll\", \"you all\")\n",
        "\n",
        "  out_text = out_text.replace(\"weren't\", \"were not\")\n",
        "  out_text = out_text.replace(\"hadn't\", \"had not\")\n",
        "  out_text = out_text.replace(\"mustn't\", \"must not\")\n",
        "  out_text = out_text.replace(\"shouldn't\", \"should not\")\n",
        "  out_text = out_text.replace(\"cain't\", \"can't\")\n",
        "  out_text = out_text.replace(\"needn't\", \"need not\")\n",
        "\n",
        "  out_text = out_text.replace(\"wouldn'ta\", \"would not have\")\n",
        "  out_text = out_text.replace(\"shouldn'a\", \"should not\")\n",
        "  out_text = out_text.replace(\"had'a\", \"had\")\n",
        "  out_text = out_text.replace(\"should'a\", \"should have\")\n",
        "  out_text = out_text.replace(\"ought'a\", \"ought to\")\n",
        "  out_text = out_text.replace(\"i'da\", \"i would have\")\n",
        "  out_text = out_text.replace(\"don'tcha\", \"don't you\")\n",
        "  out_text = out_text.replace(\"want'cha\", \"want you\")\n",
        "\n",
        "  out_text = out_text.replace(\"what'd\", \"what did\")\n",
        "  out_text = out_text.replace(\"where'd\", \"where did\")\n",
        "  out_text = out_text.replace(\"why'd\", \"why did\")\n",
        "\n",
        "  out_text = out_text.replace(\"i'ma\", \"i'm gonna\")\n",
        "  out_text = out_text.replace(\"i'mma\", \"i'm gonna\")\n",
        "  #out_text = out_text.replace(\"i'm-a\", \"i'm gonna\") # ORA HO SOSTITUITO TUTTI I \"-\" CON \" \"\n",
        "  \n",
        "  out_text = out_text.replace(\"everything's\", \"everything is\")\n",
        "  out_text = out_text.replace(\"everyone's\", \"everyone is\")\n",
        "  out_text = out_text.replace(\"here's\", \"here is\")\n",
        "  out_text = out_text.replace(\"now's\", \"now is\")\n",
        "  out_text = out_text.replace(\"body's\", \"body is\")\n",
        "  out_text = out_text.replace(\"number's\", \"number is\")\n",
        "  out_text = out_text.replace(\"back's\", \"back is\")\n",
        "  out_text = out_text.replace(\"time's\", \"time is\")\n",
        "  out_text = out_text.replace(\"rain's\", \"rain is\")\n",
        "  out_text = out_text.replace(\"whatever's\", \"whatever is\")\n",
        "\n",
        "  #out_text = out_text.replace(\"call'st\", \"calledst\") # NON PRESENTE NEL FILE WORD2VEC (NON TUTTI GLI 'st SONO edst)\n",
        "  out_text = out_text.replace(\"call'st\", \"called\")\n",
        "  out_text = out_text.replace(\"gav'st\", \"gave\")\n",
        "  out_text = out_text.replace(\"thou'st\", \"thou hast\")\n",
        "  out_text = out_text.replace(\"would'st\", \"would\")\n",
        "\n",
        "  out_text = out_text.replace(\"'twas\", \"it was\")\n",
        "  out_text = out_text.replace(\"t'was\", \"it was\")\n",
        "  out_text = out_text.replace(\"'twere\", \"it were\")\n",
        "  out_text = out_text.replace(\"'cept\", \"except\")\n",
        "  out_text = out_text.replace(\"'ceptin\", \"except\")\n",
        "  out_text = out_text.replace(\"'cross\", \"across\")\n",
        "  out_text = out_text.replace(\"'scuse\", \"scuse\")\n",
        "  out_text = out_text.replace(\"'neath\", \"beneath\")\n",
        "  out_text = out_text.replace(\"'bouts\", \"abouts\")#'''\n",
        "  out_text = out_text.replace(\"'llac\", \"cadillac\")\n",
        "  out_text = out_text.replace(\"'lac\", \"cadillac\")\n",
        "  out_text = out_text.replace(\"'em\", \" 'em\") # 'em È NEL FILE WORD2VEC MA NON TUTTE LE VARIE FORME let'em, kill'em\n",
        "  out_text = out_text.replace(\"'stead\", \"instead\")\n",
        "  out_text = out_text.replace(\"'nough\", \"enough\")\n",
        "  out_text = out_text.replace(\"'doing\", \"doing\")\n",
        "  out_text = out_text.replace(\"'cause\", \"because\")\n",
        "  out_text = out_text.replace(\"'cah\", \"cah\")\n",
        "  out_text = out_text.replace(\"'ssassin\", \"assassin\")\n",
        "  out_text = out_text.replace(\"'member\", \"remember\")\n",
        "  out_text = out_text.replace(\"'memba\", \"memba\") # remember\n",
        "  out_text = out_text.replace(\"'gin\", \"begin\")\n",
        "  out_text = out_text.replace(\"'tween\", \"between\")\n",
        "  out_text = out_text.replace(\"'leven\", \"eleven\")\n",
        "  out_text = out_text.replace(\"'yoncé\", \"beyoncé\")\n",
        "  out_text = out_text.replace(\"yoncé\", \"beyoncé\")\n",
        "  out_text = out_text.replace(\"'gator\", \"alligator\")\n",
        "  out_text = out_text.replace(\"'while\", \"a while\")\n",
        "  out_text = out_text.replace(\"'gats\", \"gats\")\n",
        "\n",
        "  out_text = out_text.replace(\"tho'\", \"though\")\n",
        "  out_text = out_text.replace(\"cuz'\", \"cuz\")\n",
        "  out_text = out_text.replace(\"gotta'\", \"gotta\")\n",
        "  out_text = out_text.replace(\"tryna'\", \"tryna\")\n",
        "  out_text = out_text.replace(\"ya'\", \" ya\")\n",
        "  out_text = out_text.replace(\"gon'\", \"gonna\")\n",
        "  out_text = out_text.replace(\"ol'\", \"old\")\n",
        "  out_text = out_text.replace(\"jag'\", \"jag\")\n",
        "  out_text = out_text.replace(\"gi'\", \"gi\")\n",
        "  out_text = out_text.replace(\"more'\", \"more\")\n",
        "  out_text = out_text.replace(\"red'\", \"red\")\n",
        "  out_text = out_text.replace(\"girlfrien'\", \"girlfriend\")\n",
        "  out_text = out_text.replace(\"wan'\", \"want\")\n",
        "  out_text = out_text.replace(\"record'\", \"records\")\n",
        "  out_text = out_text.replace(\"politic'\", \"politics\")\n",
        "  out_text = out_text.replace(\"wit'\", \"with\")\n",
        "  #out_text = out_text.replace(\"an'\", \"and\") # OCCHIO CHE SOSTITUISCE ANCHE can't CON candt, POSSO METTERE UNO SPAZIO PRIMA DI an'\n",
        "  out_text = out_text.replace(\" an'\", \" and\")\n",
        "  out_text = out_text.replace(\" n'\", \" n\") # and\n",
        "  out_text = out_text.replace(\"'n'\", \" and \") # and\n",
        "  out_text = out_text.replace(\"mam'\", \"mama\")\n",
        "  out_text = out_text.replace(\"sumn'\", \"sumn\") # something\n",
        "  out_text = out_text.replace(\"fa'\", \"fa\")     # for\n",
        "  out_text = out_text.replace(\"fo'\", \"fo\")     # for\n",
        "  out_text = out_text.replace(\"roun'\", \"round\")\n",
        "  out_text = out_text.replace(\"ho'\", \"ho\") # hoes\n",
        "  out_text = out_text.replace(\"mothafuckers'\", \"motherfuckers\")\n",
        "  out_text = out_text.replace(\"motherfuckers'\", \"motherfuckers\")\n",
        "  out_text = out_text.replace(\"mo'\", \"more\")\n",
        "  out_text = out_text.replace(\"yo'\", \"yo\")\n",
        "  out_text = out_text.replace(\"lil'\", \"lil\")\n",
        "  out_text = out_text.replace(\"billi'\", \"billions\")\n",
        "  out_text = out_text.replace(\"aroon'\", \"around\")\n",
        "  out_text = out_text.replace(\"frien'\", \"friend\")\n",
        "  out_text = out_text.replace(\"cliche'\", \"cliche\")\n",
        "  out_text = out_text.replace(\"oft'\", \"often\")\n",
        "  out_text = out_text.replace(\"looters'\", \"looters\")\n",
        "  out_text = out_text.replace(\"ta'\", \"to\")\n",
        "  out_text = out_text.replace(\"abusa'\", \"abuse\")\n",
        "  out_text = out_text.replace(\"losa'\", \"loser\")\n",
        "  out_text = out_text.replace(\"cus'\", \"cuz\")\n",
        "  out_text = out_text.replace(\"fam'\", \"family\")\n",
        "  out_text = out_text.replace(\"bis'\", \"business\")\n",
        "  out_text = out_text.replace(\"morn'\", \"morning\")\n",
        "  out_text = out_text.replace(\"quicka'\", \"quicker\")\n",
        "  out_text = out_text.replace(\"bigga'\", \"bigga\") # bigger\n",
        "  out_text = out_text.replace(\"trigga'\", \"trigga\") # trigger\n",
        "  out_text = out_text.replace(\"flo'\", \"flow\") \n",
        "  out_text = out_text.replace(\"thrilla'\", \"thrilla\")\n",
        "\n",
        "  out_text = out_text.replace(\"o' \", \"of \") # (SPAZIO ALLA FINE PER EVITARE DI SOSTITUIRE PAROLE COME o'shea)\n",
        "  out_text = out_text.replace(\" em'\", \" 'em'\") # (SPAZIO DAVANTI PER EVITARE DI SOSTITUIRE PAROLE COME 'em')\n",
        "  out_text = out_text.replace(\"do'\", \"door\") # (NON SO SE SEMPRE PUÒ ESSERE SOSTITUITA COSÌ)\n",
        "  out_text = out_text.replace(\"wha'\", \"wha\")\n",
        "  out_text = out_text.replace(\"mil'\", \"mil\") # million\n",
        "    \n",
        "  out_text = out_text.replace(\"c'mon\", \"come on\")\n",
        "  out_text = out_text.replace(\"mem'ry\", \"memory\")\n",
        "  out_text = out_text.replace(\"mem'ries\", \"memories\")\n",
        "  out_text = out_text.replace(\"ev'ry\", \"every\")\n",
        "  out_text = out_text.replace(\"e'ry\", \"every\")\n",
        "  out_text = out_text.replace(\"ev'y\", \"every\")\n",
        "  #out_text = out_text.replace(\"e'ery\", \"every\") # INCLUSO SOTTO\n",
        "  out_text = out_text.replace(\"e'er\", \"ever\")\n",
        "  #out_text = out_text.replace(\"ne'er\", \"never\")       # INCLUSO SOPRA\n",
        "  #out_text = out_text.replace(\"whate'er\", \"whatever\") # INCLUSO SOPRA\n",
        "  #out_text = out_text.replace(\"fore'er\", \"\")          # INCLUSO SOPRA\n",
        "  out_text = out_text.replace(\"myst'ry\", \"mystery\")\n",
        "  out_text = out_text.replace(\"m'sippi\", \"mississippi\")\n",
        "  #out_text = out_text.replace(\"let'em\", \"let them\") # INCLUSO SOPRA\n",
        "  out_text = out_text.replace(\"whatev's\", \"whatevs\")\n",
        "  out_text = out_text.replace(\"o'clock\", \"oclock\")\n",
        "  out_text = out_text.replace(\"prob'ly\", \"probably\")\n",
        "  out_text = out_text.replace(\"ki's\", \"kilos\")\n",
        "  out_text = out_text.replace(\"meetin's\", \"meetings\")\n",
        "  out_text = out_text.replace(\"fam'ly\", \"family\")\n",
        "  out_text = out_text.replace(\"o'er\", \"over\")\n",
        "  out_text = out_text.replace(\"slip'n \", \"slip'n'\")\n",
        "  out_text = out_text.replace(\"fa'sho\", \"for sure\")\n",
        "  out_text = out_text.replace(\"fo'sure\", \"for sure\")\n",
        "  out_text = out_text.replace(\"fa'sure\", \"for sure\")\n",
        "  out_text = out_text.replace(\"fin'lly\", \"finally\")\n",
        "  out_text = out_text.replace(\"awf'lly\", \"awfully\")\n",
        "  out_text = out_text.replace(\"logic'lly\", \"logically\")\n",
        "  out_text = out_text.replace(\"trav'llin\", \"travellin\")\n",
        "  out_text = out_text.replace(\"natur'lly\", \"naturally\")\n",
        "  out_text = out_text.replace(\"natu'lly\", \"naturally\")\n",
        "  out_text = out_text.replace(\"f'real\", \"for real\")\n",
        "  out_text = out_text.replace(\"fo'real\", \"for real\")\n",
        "  out_text = out_text.replace(\"fa'real\", \"for real\")\n",
        "  #out_text = out_text.replace(\"diff'rent\", \"different\")   # INCLUSO SOTTO\n",
        "  #out_text = out_text.replace(\"diff'rence\", \"difference\") # INCLUSO SOTTO\n",
        "  out_text = out_text.replace(\"diff'ren\", \"differen\")\n",
        "  #out_text = out_text.replace(\"pref'rence\", \"preference\") # INCLUSO SOTTO\n",
        "  out_text = out_text.replace(\"ref'rence\", \"reference\")\n",
        "  out_text = out_text.replace(\"chil'ren\", \"children\")\n",
        "  out_text = out_text.replace(\"chi'ren\", \"children\")\n",
        "  out_text = out_text.replace(\"int'rest\", \"interest\")\n",
        "  out_text = out_text.replace(\"mack'rel\", \"mackerel\")\n",
        "  out_text = out_text.replace(\"sov'reign\", \"sovereign\")\n",
        "  out_text = out_text.replace(\"des'ree\", \"desiree\")\n",
        "  out_text = out_text.replace(\"wand'rer\", \"wanderer\")\n",
        "  out_text = out_text.replace(\"wand'ring\", \"wandering\")\n",
        "  #out_text = out_text.replace(\"l've\", \"love\") # INCLUSO NEL CICLO\n",
        "  #out_text = out_text.replace(\"lo'es\", \"loves\") # INCLUSO SOTTO\n",
        "  out_text = out_text.replace(\"lo'e\", \"love\")\n",
        "  out_text = out_text.replace(\"lov'd\", \"loved\")\n",
        "  out_text = out_text.replace(\"b'day\", \"birthday\")\n",
        "  out_text = out_text.replace(\"full'a\", \"full of\")\n",
        "  out_text = out_text.replace(\"creep'n\", \"creeping\")\n",
        "  out_text = out_text.replace(\"loc'ed\", \"locked\")\n",
        "  out_text = out_text.replace(\"ye'se\", \"you shall\")\n",
        "  out_text = out_text.replace(\"ta'en\", \"taken\")\n",
        "  out_text = out_text.replace(\"e'en\", \"even\")\n",
        "  out_text = out_text.replace(\"de'il\", \"devil\")\n",
        "  out_text = out_text.replace(\"ma'am\", \"madam\")\n",
        "  out_text = out_text.replace(\"cap'n\", \"captain\")\n",
        "  out_text = out_text.replace(\"sev'ral\", \"several\")\n",
        "  out_text = out_text.replace(\"monsta'\", \"monsta\")\n",
        "  out_text = out_text.replace(\"closa'\", \"close\")\n",
        "  out_text = out_text.replace(\"s'posed\", \"supposed\")\n",
        "  out_text = out_text.replace(\"s'pposed\", \"supposed\")\n",
        "  out_text = out_text.replace(\"wonda'\", \"wonder\")\n",
        "  out_text = out_text.replace(\"kind'a\", \"kind of\")\n",
        "  out_text = out_text.replace(\"irregula'\", \"irregular\")\n",
        "  out_text = out_text.replace(\"gon'be\", \"gonna be\")\n",
        "  out_text = out_text.replace(\"fright'ning\", \"frightening\")\n",
        "  out_text = out_text.replace(\"sump'n\", \"something\")\n",
        "  out_text = out_text.replace(\"some'n\", \"something\")\n",
        "  out_text = out_text.replace(\"s'all\", \"it is all\")\n",
        "  out_text = out_text.replace(\"do'ya\", \"do you\")\n",
        "  out_text = out_text.replace(\"trav'lin\", \"traveling\")\n",
        "  #out_text = out_text.replace(\"trav'ling\", \"traveling\") # INCLUSO SOPRA\n",
        "  out_text = out_text.replace(\"wond'rin\", \"wondering\")\n",
        "  out_text = out_text.replace(\"ling'ring\", \"lingering\")\n",
        "  out_text = out_text.replace(\"strawb'ries\", \"strawberries\")\n",
        "  out_text = out_text.replace(\"smould'ring\", \"smouldering\")\n",
        "  out_text = out_text.replace(\"nam'd\", \"named\")\n",
        "  out_text = out_text.replace(\"appear'd\", \"appeared\")\n",
        "  out_text = out_text.replace(\"announc'd\", \"announced\")\n",
        "  out_text = out_text.replace(\"fulfill'd\", \"fulfilled\")\n",
        "  out_text = out_text.replace(\"rul'd\", \"ruled\")\n",
        "  out_text = out_text.replace(\"releas'd\", \"released\")\n",
        "  out_text = out_text.replace(\"banish'd\", \"banished\")\n",
        "  out_text = out_text.replace(\"restor'd\", \"restored\")\n",
        "  out_text = out_text.replace(\"nourish'd\", \"nourished\")\n",
        "  out_text = out_text.replace(\"fear'd\", \"feared\")\n",
        "  out_text = out_text.replace(\"pro'ly\", \"probably\")\n",
        "  out_text = out_text.replace(\"wit'chu\", \"with you\")\n",
        "  out_text = out_text.replace(\"b'ness\", \"business\")\n",
        "  out_text = out_text.replace(\"a'ight\", \"alright\")\n",
        "  out_text = out_text.replace(\"suff'ring\", \"suffering\")\n",
        "  out_text = out_text.replace(\"mem'rable\", \"memorable\")\n",
        "  out_text = out_text.replace(\"alabam'\", \"alabama\")\n",
        "  out_text = out_text.replace(\"arizon'\", \"arizona\")\n",
        "  out_text = out_text.replace(\"louisian'\", \"louisiana\")\n",
        "  out_text = out_text.replace(\"groc'ries\", \"groceries\")\n",
        "  out_text = out_text.replace(\"s'rambling\", \"scrambling\")\n",
        "  out_text = out_text.replace(\"t'night\", \"tonight\")\n",
        "  out_text = out_text.replace(\"anotha'\", \"another\")\n",
        "  out_text = out_text.replace(\"t'ward\", \"toward\")\n",
        "  out_text = out_text.replace(\"why'm\", \"why am\")\n",
        "  out_text = out_text.replace(\"hap'nin\", \"happening\")\n",
        "  out_text = out_text.replace(\"whad'ya\", \"what do you\")\n",
        "  out_text = out_text.replace(\"mothafucka'\", \"mothafucka\")\n",
        "  out_text = out_text.replace(\"muhh'fucka\", \"mothafucka\")\n",
        "  out_text = out_text.replace(\"'lectricity\", \"electricity\")\n",
        "  out_text = out_text.replace(\"didn'tcha\", \"didn't you\")\n",
        "  out_text = out_text.replace(\"choc'late\", \"chocolate\")\n",
        "  out_text = out_text.replace(\"bi'ness\", \"business\")\n",
        "  out_text = out_text.replace(\"b'iness\", \"business\")\n",
        "  out_text = out_text.replace(\"light'ning\", \"lightning\")\n",
        "  out_text = out_text.replace(\"big'un\", \"big one\")\n",
        "  out_text = out_text.replace(\"slipp'ry\", \"slippery\")\n",
        "  out_text = out_text.replace(\"joyf'ly\", \"joyfully\")\n",
        "  out_text = out_text.replace(\"nor'wester\", \"Northwester\")\n",
        "  out_text = out_text.replace(\"thund'ry\", \"thundery\")\n",
        "  out_text = out_text.replace(\"fi'th\", \"fifth\")\n",
        "  out_text = out_text.replace(\"y'know\", \"you know\")\n",
        "  out_text = out_text.replace(\"play'd\", \"played\")\n",
        "  out_text = out_text.replace(\"who'da\", \"who would have\")\n",
        "  out_text = out_text.replace(\"light'nin\", \"lightning\")\n",
        "  #out_text = out_text.replace(\"i'm'a\", \"\") # i'm gonna O i'm a?\n",
        "  out_text = out_text.replace(\"fuckin'day\", \"fucking day\")\n",
        "  out_text = out_text.replace(\"aw'right\", \"all right\")\n",
        "  out_text = out_text.replace(\"gi'me\", \"give me\")\n",
        "  out_text = out_text.replace(\"a'waitin\", \"awaiting\")\n",
        "  out_text = out_text.replace(\"n'ggas\", \"niggas\")\n",
        "  #out_text = out_text.replace(\"ass'quake\", \"assquake\") # NON PRESENTE NEL FILE WORD2VEC\n",
        "  out_text = out_text.replace(\"ass'quake\", \"twerk\")\n",
        "  out_text = out_text.replace(\"ha'pennies\", \"halfpennies\")\n",
        "  out_text = out_text.replace(\"wanderin'up\", \"wandering up\")\n",
        "  out_text = out_text.replace(\"p'liceman\", \"policeman\")\n",
        "  out_text = out_text.replace(\"oughn't\", \"ough not\")\n",
        "  out_text = out_text.replace(\"p'hapz\", \"perhaps\")\n",
        "  out_text = out_text.replace(\"what'sup\", \"what's up\")\n",
        "  out_text = out_text.replace(\"mo'nin\", \"morning\")\n",
        "  out_text = out_text.replace(\"bless'n\", \"blessing\")\n",
        "  out_text = out_text.replace(\"sittin'on\", \"sitting on\")\n",
        "  out_text = out_text.replace(\"challeng'd\", \"challenged\")\n",
        "  out_text = out_text.replace(\"terr'ble\", \"terrible\")\n",
        "  out_text = out_text.replace(\"tell'n\", \"telling\")\n",
        "  out_text = out_text.replace(\"gall'ry\", \"gallery\")\n",
        "  out_text = out_text.replace(\"try'n\", \"trying\")\n",
        "  out_text = out_text.replace(\"sick'ning\", \"sickening\")\n",
        "  out_text = out_text.replace(\"g'mornin\", \"good morning\")\n",
        "  out_text = out_text.replace(\"'liminate\", \"eliminate\")\n",
        "  out_text = out_text.replace(\"d'stroy\", \"destroy\")\n",
        "  out_text = out_text.replace(\"ass'state\", \"ass state\")\n",
        "  out_text = out_text.replace(\"d'you\", \"do you\") # MA POTREBBE ESSERE ANCHE did you\n",
        "  out_text = out_text.replace(\"x'tra\", \"extra\")\n",
        "  out_text = out_text.replace(\"n'don't\", \"and don't\")\n",
        "  out_text = out_text.replace(\"loo'd\", \"looed\")\n",
        "  #out_text = out_text.replace(\"droon'd\", \"drooned\") # MANCANTE\n",
        "  out_text = out_text.replace(\"droon'd\", \"drowned\")\n",
        "  out_text = out_text.replace(\"ladies' man\", \"seducer\")\n",
        "  out_text = out_text.replace(\"it'e\", \"it's\")\n",
        "  out_text = out_text.replace(\"i'e\", \"i've\")\n",
        "  out_text = out_text.replace(\"y'get\", \"you get\")\n",
        "  out_text = out_text.replace(\"y'say\", \"you say\")\n",
        "  out_text = out_text.replace(\"bid'ness\", \"bidness\")\n",
        "  out_text = out_text.replace(\"pu**y\", \"pussy\")\n",
        "  out_text = out_text.replace(\"emotion'ly\", \"emotionally\")\n",
        "  out_text = out_text.replace(\"fin'ly\", \"finally\")\n",
        "  \n",
        "  # ORA HO SOSTITUITO TUTTI I \"-\" CON \" \"\n",
        "  '''out_text = out_text.replace(\"bone-out\", \"bone out\")\n",
        "  out_text = out_text.replace(\"lo-lo\", \"lolo\") # low rider car\n",
        "  out_text = out_text.replace(\"g-ster\", \"gangster\")\n",
        "  out_text = out_text.replace(\"motherfu-\", \"motherfucker\")\n",
        "  out_text = out_text.replace(\"chi-raq\", \"Chiraq\")'''\n",
        "\n",
        "  # Capitalize missing words\n",
        "  out_text = out_text.replace(\"chiraq\", \"Chiraq\")\n",
        "  out_text = out_text.replace(\"norsemen\", \"Norsemen\")\n",
        "  out_text = out_text.replace(\"dolemite\", \"Dolemite\")\n",
        "  out_text = out_text.replace(\"kahlil\", \"Khalil\")\n",
        "  out_text = out_text.replace(\"vedders\", \"Vedder\")\n",
        "  out_text = out_text.replace(\"cobains\", \"Cobain\")\n",
        "  #out_text = out_text.replace(\"dahrouge\", \"Dahrouge\") MISSING\n",
        "  out_text = out_text.replace(\"yamazaki\", \"Yamazaki\")\n",
        "  out_text = out_text.replace(\"oshun\", \"Oshun\")\n",
        "  out_text = out_text.replace(\"rafah\", \"Rafah\")\n",
        "  out_text = out_text.replace(\"brigadoon\", \"Brigadoon\")\n",
        "  out_text = out_text.replace(\"brignac\", \"Brignac\")  \n",
        "  out_text = out_text.replace(\"portmore\", \"Portmore\")\n",
        "  out_text = out_text.replace(\"defari\", \"Defari\")\n",
        "  out_text = out_text.replace(\"r&b\", \"RnB\")\n",
        "\n",
        "  out_text = out_text.replace(\"copycating\", \"copy cating\")\n",
        "  out_text = out_text.replace(\"grabba\", \"tobacco\")\n",
        "  out_text = out_text.replace(\"f**k\", \"fuck\")\n",
        "  out_text = out_text.replace(\"whatna\", \"what kind of\")\n",
        "  out_text = out_text.replace(\"twizza\", \"pussy\")\n",
        "  out_text = out_text.replace(\"hallucigent\", \"hallucinogen\")\n",
        "  out_text = out_text.replace(\"psychadelically\", \"psychedelically\")\n",
        "  out_text = out_text.replace(\"skanless\", \"shocking\")\n",
        "  out_text = out_text.replace(\"dooky\", \"dookie\")\n",
        "  out_text = out_text.replace(\"thugsta\", \"gangster\")\n",
        "  out_text = out_text.replace(\"thugster\", \"gangster\")\n",
        "  out_text = out_text.replace(\"mugster\", \"robber\")\n",
        "  out_text = out_text.replace(\"downest\", \"coolest\")\n",
        "  out_text = out_text.replace(\"mothafucking\", \"motherfucking\")\n",
        "  out_text = out_text.replace(\"muthaphuckkin\", \"motherfucking\")\n",
        "  out_text = out_text.replace(\"dopeman\", \"dope man\")\n",
        "  out_text = out_text.replace(\"cluckhead\", \"crackhead\")\n",
        "  out_text = out_text.replace(\"mothafucker\", \"mothafucka\")\n",
        "  out_text = out_text.replace(\"mutherfucka\", \"mothafucka\")\n",
        "  out_text = out_text.replace(\"tamika\", \"gorgeous\")\n",
        "  out_text = out_text.replace(\"hunnid\", \"hundred\")\n",
        "  out_text = out_text.replace(\"geah\", \"yeah\")\n",
        "  out_text = out_text.replace(\"ugk\", \"underground kings\")\n",
        "  out_text = out_text.replace(\"whoadie\", \"friend\")\n",
        "  out_text = out_text.replace(\" lluminati\", \" illuminati\")\n",
        "  out_text = out_text.replace(\"motherfunk\", \"motherfuck\")\n",
        "  out_text = out_text.replace(\"spinfire\", \"spinning fire\")\n",
        "  out_text = out_text.replace(\"brilling\", \"brilliant\")\n",
        "  out_text = out_text.replace(\"embrangled\", \"embroiled\")\n",
        "  out_text = out_text.replace(\"modicum\", \"bean\")\n",
        "  out_text = out_text.replace(\"mecedes\", \"mercedes\")\n",
        "  out_text = out_text.replace(\"pineing\", \"pining\")\n",
        "  out_text = out_text.replace(\"karot\", \"karat\")\n",
        "  out_text = out_text.replace(\"smilled\", \"smiled\")\n",
        "  out_text = out_text.replace(\"trembing\", \"trembling\")\n",
        "  out_text = out_text.replace(\"towsack\", \"tow sack\")\n",
        "  out_text = out_text.replace(\"bloodlet\", \"bloodletting\")\n",
        "  out_text = out_text.replace(\"dirtpile\", \"dirt pile\")\n",
        "  out_text = out_text.replace(\"inutterable\", \"unutterable\")\n",
        "  out_text = out_text.replace(\"profitous\", \"profitable\")\n",
        "  out_text = out_text.replace(\"unlash\", \"unleash\")\n",
        "  out_text = out_text.replace(\"delphinidins\", \"delphinidin\")\n",
        "  out_text = out_text.replace(\"phillistines\", \"philistines\")\n",
        "  out_text = out_text.replace(\"shwip\", \"thanks\")\n",
        "  out_text = out_text.replace(\"hoah\", \"woah\")\n",
        "  out_text = out_text.replace(\"favirite\", \"favorite\")\n",
        "  out_text = out_text.replace(\"strenthened\", \"strengthened\")\n",
        "  out_text = out_text.replace(\"bolb\", \"bomb\")\n",
        "  out_text = out_text.replace(\"bebeyoncé\", \"beyoncé\")\n",
        "  out_text = out_text.replace(\"cowpoking\", \"lazy\")\n",
        "  out_text = out_text.replace(\"couchie\", \"vagina\")\n",
        "  out_text = out_text.replace(\"strictly dickly\", \"attracted only to men\")\n",
        "  out_text = out_text.replace(\"doublemint\", \"cocaine\")\n",
        "  out_text = out_text.replace(\"kimosabe\", \"friend\")\n",
        "  out_text = out_text.replace(\"permastoned\", \"permanently stoned\")\n",
        "  out_text = out_text.replace(\"whappen\", \"what's happening\")\n",
        "  out_text = out_text.replace(\"audiotune\", \"audio tune\")\n",
        "  out_text = out_text.replace(\"birdback\", \"bird back\")\n",
        "  out_text = out_text.replace(\"spirtualism\", \"spiritualism\")\n",
        "  out_text = out_text.replace(\"surviellance\", \"surveillance\")\n",
        "  out_text = out_text.replace(\"skrrt\", \"wheels screeching\")\n",
        "  out_text = out_text.replace(\"skrt\", \"wheels screeching\")\n",
        "  out_text = out_text.replace(\"im\", \"i'm\")  # CONTIENE CARATTERI SPECIALI\n",
        "  out_text = out_text.replace(\"its\", \"it's\")  # CONTIENE CARATTERI SPECIALI\n",
        "  out_text = out_text.replace(\"dont\", \"don't\")  # CONTIENE CARATTERI SPECIALI\n",
        "  out_text = out_text.replace(\"backaz\", \"backaS\")\n",
        "  out_text = out_text.replace(\"blaow\", \"boom\")\n",
        "  out_text = out_text.replace(\"wrecka\", \"wreck\")\n",
        "  out_text = out_text.replace(\"wwoah\", \"woah\")\n",
        "  out_text = out_text.replace(\"cuyah\", \"look here\")\n",
        "  out_text = out_text.replace(\"aiyyo\", \"aiyo\")\n",
        "  out_text = out_text.replace(\"bzzy\", \"buzzy\")\n",
        "  out_text = out_text.replace(\"gangsto\", \"gangster\")\n",
        "  out_text = out_text.replace(\"dkm\", \"don't know me\") # IL TESTO CONTIENE DELLE ABBREVIAZIONI CON LEGENDA ALL'INIZIO DEL TESTO (IL TESTO REALE INIZIA PIÙ AVANTI, ANDREBBE TAGLIATA LA PRIMA PARTE)\n",
        "\n",
        "\n",
        "  \n",
        "  # Put a space before 's and 'd to recognize remaining words + 's or 'd (OCCHIO SOSTITUISCE ANCHE it's e altri)\n",
        "  # ALTRA TECNICA COMBINANDO I VETTORI WORD2VEC\n",
        "  #out_text = out_text.replace(\"'s\", \" 's\") \n",
        "  #out_text = out_text.replace(\"'d\", \" 'd\")\n",
        "\n",
        "  #out_text = out_text.replace(\"\", \"\")\n",
        "  \n",
        "  #out_text = out_text.replace(\"i'd\", \"i would\") # but can also be 'i had'\n",
        "  #out_text = out_text.replace(\"ain't\", \"am not\") # but ain't can also be 'are not', 'is not', ...\n",
        "\n",
        "  # NEI TESTI CI SONO ANCHE DEGLI ERRORI DI BATTITURA, QUINDI ALCUNE SEQUENZE SIAMO COSTRETTI A SALTARLE\n",
        "\n",
        "  #if '\"' in text:\n",
        "  #if \"in'\" in text:\n",
        "  #if \"60'\" in text:\n",
        "  #if \"3x\" in text:\n",
        "  #if \"x3\" in text.lower():\n",
        "  #if \"'ve\" in text.lower():\n",
        "  #if \"why're\" in text.lower():\n",
        "  #if \"'ll\" in text.lower():\n",
        "  #if \"ya'll\" in text.lower() or \"y'all\" in text.lower():\n",
        "  #if \"weren't\" in text.lower() or \"mustn't\" in text.lower() or \"shouldn't\" in text.lower():\n",
        "  #if \"everything's\" in text.lower() or \"here's\" in text.lower():\n",
        "  #if \"'twas\" in text.lower() or \"'ceptin'\" in text.lower():\n",
        "  #if \"38s'll\" in text.lower() or \"5th'll\" in text.lower() or \"187'll\" in text.lower():\n",
        "  #if \"i got a story a story to tell about a long road back from a sory of hell i been flying almost every night\" in text.lower():\n",
        "  #if \"'\\\"\" in text:\n",
        "  \n",
        "  #if \"g'mornin\" in text.lower():# or \"\" in text.lower() or \"'st\" in text.lower() or \"\" in text.lower():\n",
        "\n",
        "  #if \"forty-four lies\" in text.lower() or \"before i fall away\" in text.lower():\n",
        "  #if \"*\" in text:\n",
        "  #if \"you know they are not even interested in votin\" in text.lower():\n",
        "  #if \"interested in votin\" in text.lower():\n",
        "  #if \"alchemist.\" in text:\n",
        "  \n",
        "  #if \"when i'm behind the wheel i'm in the fast lane got the the radio on to bob tench\" in out_text or \\\n",
        "  #   \"busted the safe stole the key to the city made out with your sister the one i think is pretty i think\" in out_text or \\\n",
        "  #   \"baby baby's looking better than fine she's got a brand new dress and she's ready to shine got her heart broke bad by some silly guy didn't know who the\" in out_text or \\ # Errore nel testo (anche online): noody invece di nobody\n",
        "  #   \"washington d c is pretty but it ain't my city i need a town here where i can get down i follow traces of faces of people baby and when they get it on the world turns brown in my \" in out_text \\ # Errore nel testo (anche online): washingto invece di washington\n",
        "  #   \"she got out of the car w a cocaine nose and a nosejob she wore her pants so tight wasn't too bright it doesn't matter much when you're\" in out_text \\ # Errore nel testo (anche online): allrigt invece di allright\n",
        "  #   \"melody griffins sing a song of liberty ga ga ga ga eclectic melody's popping out oh hairy lips oompah\" in out_text \\ #  Errore nel testo: see'est invece di c'est\n",
        "  #   :\n",
        "    #print(\"text before preprocessing: \", text)\n",
        "    #print(\"text after preprocessing: \", out_text)\n",
        "    #print(\"*\"*40)\n",
        "\n",
        "  #  print(\"*\"*40)\n",
        "  #  print(\"text before preprocessing:\")\n",
        "  #  print(text)\n",
        "  #  print(\"=\"*40)\n",
        "  #  print(\"text after preprocessing:\")\n",
        "  #  print(out_text)\n",
        "  #  print(\"*\"*40)\n",
        "\n",
        "  #print(\"=\"*40)\n",
        "  #print(\"lyrics after preprocessing:\\n\", out_text)\n",
        "\n",
        "  '''print(\"*\"*40)\n",
        "  print(\"text before preprocessing:\")\n",
        "  print(text)\n",
        "  print(\"=\"*40)\n",
        "  print(\"text after preprocessing:\")\n",
        "  print(out_text)'''\n",
        "  \n",
        "  return out_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--dlFgWdHcwX"
      },
      "source": [
        "Read input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OzkES3SYSEz"
      },
      "source": [
        "# Read CSV file and get columns of interest\n",
        "data = pd.read_csv(dataset_path)\n",
        "#data = pd.read_csv(input_dataset_path) # PER TEST TRA TESTI PRIMA PREPROCESSING E DOPO\n",
        "\n",
        "data = data[['genre', 'lyrics']][:5000].dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGNB6y4iG540"
      },
      "source": [
        "Display input data (optionally using an interactive table)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6l6LT87G1hc"
      },
      "source": [
        "#from google.colab.data_table import DataTable\n",
        "#DataTable(data)\n",
        "\n",
        "data[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjVSiPIsHhUz"
      },
      "source": [
        "Preprocess input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVcqE3J6HDtr"
      },
      "source": [
        "# Preprocess lyrics\n",
        "print(\"Preprocessing lyrics...\")\n",
        "data['lyrics'] = data['lyrics'].apply(lyrics_preprocessing)\n",
        "\n",
        "#print(\"\\data:\")\n",
        "#print(data[:10])\n",
        "\n",
        "# Removing non-english lyrics\n",
        "print(\"Removing non-english lyrics detected during preprocessing...\")\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "print(\"\\data:\")\n",
        "print(data[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ghQNuhHQH5"
      },
      "source": [
        "Display preprocessed data (optionally using an interactive table)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa_e8yoJHMJn"
      },
      "source": [
        "#data = pd.read_csv(dataset_path) # PER TEST TRA TESTI PRIMA PREPROCESSING E DOPO\n",
        "\n",
        "#from google.colab.data_table import DataTable\n",
        "#DataTable(data)\n",
        "\n",
        "data[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_EJOaEzRtG6"
      },
      "source": [
        "Store preprocessed lyrics into a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sze9oLF8LPJ6"
      },
      "source": [
        "data.to_csv(preprocessed_dataset_path, mode=\"w+\", encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
